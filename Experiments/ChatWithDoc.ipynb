{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyCwUyEJgow4reA7zx3BTXzy8mwNWZhxLIo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Personal projects\\QA_With_Doc_using_llama_index_gemini\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "import google.generativeai as genai\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "#from llama_index.core.settings import Settings\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
      "                   'February 15th, 2025. Move to a newer Gemini version.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
      "                   'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
      "                   'version.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
      "                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
      "                   'Move to a newer Gemini version.'),\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
      "                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
      "                   'Move to a newer Gemini version.'),\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
      "                   'million tokens.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro 001',\n",
      "      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
      "                   'supports up to 2 million tokens, released in May of 2024.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-002',\n",
      "      base_model_id='',\n",
      "      version='002',\n",
      "      display_name='Gemini 1.5 Pro 002',\n",
      "      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
      "                   'supports up to 2 million tokens, released in September of 2024.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
      "                   'supports up to 2 million tokens, released in May of 2024.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-pro-exp-0801',\n",
      "      base_model_id='',\n",
      "      version='exp-0801',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-exp-0827',\n",
      "      base_model_id='',\n",
      "      version='exp-1206',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
      "                   'across diverse tasks.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001',\n",
      "      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
      "                   'for scaling across diverse tasks, released in May of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-001-tuning',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001 Tuning',\n",
      "      description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
      "                   'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
      "      input_token_limit=16384,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
      "                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-exp-0827',\n",
      "      base_model_id='',\n",
      "      version='exp-1206',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-002',\n",
      "      base_model_id='',\n",
      "      version='002',\n",
      "      display_name='Gemini 1.5 Flash 002',\n",
      "      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
      "                   'for scaling across diverse tasks, released in September of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-8b',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B',\n",
      "      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
      "                   'Flash model, released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-8b-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B 001',\n",
      "      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
      "                   'Flash model, released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-8b-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
      "                   'released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
      "      description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
      "                   'smallest and most cost effective Flash model. Replaced by '\n",
      "                   'Gemini-1.5-flash-8b-001 (stable).'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
      "      description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
      "                   'smallest and most cost effective Flash model. Replaced by '\n",
      "                   'Gemini-1.5-flash-8b-001 (stable).'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-2.0-flash-exp',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash Experimental',\n",
      "      description='Gemini 2.0 Flash Experimental',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/gemini-exp-1206',\n",
      "      base_model_id='',\n",
      "      version='exp_1206',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-exp-1121',\n",
      "      base_model_id='',\n",
      "      version='exp-1206',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-exp-1114',\n",
      "      base_model_id='',\n",
      "      version='exp-1206',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (December 6th, 2024) of Gemini.',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-2.0-flash-thinking-exp',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash Thinking Experimental',\n",
      "      description='Gemini 2.0 Flash Thinking Experimental',\n",
      "      input_token_limit=32767,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash Thinking Experimental',\n",
      "      description='Gemini 2.0 Flash Thinking Experimental',\n",
      "      input_token_limit=32767,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/learnlm-1.5-pro-experimental',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='LearnLM 1.5 Pro Experimental',\n",
      "      description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
      "                   'mid-size multimodal model that supports up to 2 million tokens.'),\n",
      "      input_token_limit=32767,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "for models in genai.list_models():\n",
    "  print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-exp-1206\n",
      "models/gemini-exp-1121\n",
      "models/gemini-exp-1114\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n"
     ]
    }
   ],
   "source": [
    "for models in genai.list_models():\n",
    "  if 'generateContent' in models.supported_generation_methods:\n",
    "    print(models.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../Data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='3d2c8a0f-37ac-42a5-9caa-71dff5e39d0e', embedding=None, metadata={'page_label': '1', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1  \\n \\nDIGITAL NOTES \\nON \\nMachine Learning \\n(R20D5803) \\nM.Tech., II YEAR – I SEM \\n(2021-2022) \\n \\n \\n \\nDEPARTMENT OF COMPUTER SCIENCE AND \\nENGINEERING \\n \\nMALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \\n(Autonomous Institution – UGC, Govt. of India) \\n(Affiliated to JNTUH, Hyderabad, Approved by AICTE - Accredited by NBA & NAAC – ‘A’ Grade - ISO 9001:2015 Certified) \\nMaisammaguda, Dhulapally (Post Via. Hakimpet), Secunderabad – 500100, Telangana State, INDIA. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ecd0ce07-01c5-4a6e-92ed-6723bb768e94', embedding=None, metadata={'page_label': '2', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='2  \\nMALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\nSYLLABUS  \\nII Year M. Tech. CSE – I Sem L/T/P/ C \\n3 / - / -  3 \\n(R20D5803) Machine Learning \\nObjectives: \\n1. This course explains machine learning techniques such as decision tree learning, \\nBayesian learning etc. \\n2. To understand computational learning theory. \\n3. To study the pattern comparison techniques. \\n \\nUNIT - I \\nIntroduction Well -posed learning problems, designing a learning  system Perspectives and issues  in \\nmachine learning Concept learning and the general to specific ordering Introduction,A concept learning  \\ntask, concept learning as search, Find -S: Finding a Maximally Specific Hypothes is, Version Spaces and  \\nthe Candidate Elimination algorithm, Remarks on  Version Spaces and Candidate Elimination, Inductive  \\nBias. Decision Tree Learning-Introduction, Decision Tree Representation, Appropriate Problems for  \\nDecision Tree Learning, The Basic D ecision Tree Learning Algorithm Hypothesis Space  Search in \\nDecision Tree Learning, Inductive Bias in Decision Tree Learning, Issues in Decision Tree Learning. \\n \\nUNIT - II \\nArtificial Neural Networks -Introduction, Neural Network  Representation, Appropriate Problems for  \\nNeural Network Learning, Perceptions, Multilayer Networks and the Back propagation Algorithm. \\nDiscussion on the Back Propagation Algorithm, An illustrative Example: Face Recognition \\n \\nUNIT - III \\nBayesian learning-Introduction, Byes Theorem, Bayes Theorem and Concept Learning Maximum \\nLikelihood and Least Squared Error Hypotheses, Maximum Likelihood Hypotheses for Predicting \\nProbabilities, Minimum Description Length Principle, Bayes Optimal Classifier, Gibs Algorithm, Naïve  \\nBayes Classifier, An Example: Learning to Classify Text, Bayesian Belief Networks, EM Algorithm. \\nInstance-Based Learning-Introduction, k-Nearest Neighbor Learning, Locally Weighted Regression, \\nRadial Basis Functions, Case-Based Reasoning, Remarks on Lazy and Eager Learning. \\n \\nUNIT -IV \\nPattern Comparison Techniques-Temporal patterns, Dynamic Time Warping Methods,Clustering, \\nIntroduction to clustering, K-means clustering, K-Mode Clustering. Codebook Generation, Vector \\nQuantization. \\n \\nUNIT - V \\nGenetic Algorithms: Different search m ethods for induction  - Explanation-based Learning: using prior  \\nknowledge to reduce sample complexity. Dimensionality reduction: feature selection, principal \\ncomponent analysis, linear discriminate analysis, factor analysis, independent component analysis, \\nmultidimensional scaling, and manifold learning. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='cb27a2aa-c05e-47f6-a556-36d9b6d2312e', embedding=None, metadata={'page_label': '3', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='3  \\n \\n \\n \\nTextbooks: \\n1. Machine Learning – Tom M. Mitchell, -MGH \\n2. Fundamentals of Speech Recognition By Lawrence Rabiner and Biing – Hwang \\nJuang .Ethem Alpaydin, ”Introduction to Machine Learning”, MIT Press, \\nPrentice Hall of India, 3 rd Edition2014. \\n3.  Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar ” Foundations of Machine \\nLearning”,MIT Press,2012 \\nReferences: \\n1. Machine Learning : An Algorithmic Perspective, Stephen Marsland, Taylor & Francis . ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f4f40fbc-9ae5-4bb4-8f35-7995814bdf7c', embedding=None, metadata={'page_label': '4', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='4  \\n \\n \\nINDEX \\n \\n \\nS. No \\n \\nUnit \\n \\nTopic \\n \\nPage no \\n \\n1 I Introduction Well-posed learning problems 1 \\n2 I A concept learning task, concept learning as search 6 \\n3 I Find-S: Finding a Maximally Specific Hypothesis 15 \\n4 I Version Spaces and the Candidate Elimination \\nalgorithm \\n17 \\n5 I Remarks on Version Spaces and Candidate \\nElimination, Inductive Bias \\n21 \\n6 I Decision Tree Learning-Introduction, Decision Tree \\nRepresentation \\n22 \\n7 I Appropriate Problems for Decision Tree Learning 23 \\n8 I Decision Tree Learning Algorithm, Issues in Decision \\nTree Learning. 25 \\n \\n \\n \\n \\n \\n \\nS. No \\n \\nUnit \\n \\nTopic \\n \\nPage no \\n \\n1 II Artificial Neural Networks -Introduction, \\nNeural Network Representation \\n26 \\n \\n2 II  \\nAppropriate Problems for Neural Network \\nLearning \\n \\n28 \\n3 II Perceptions, Multilayer Networks & the Back \\npropagation Algorithm. \\n29 \\n4 II Discussion on the Back Propagation Algorithm 34 \\nMALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e5f697f0-92f8-4726-af63-7f17aa23eb5e', embedding=None, metadata={'page_label': '5', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='5  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nS. No \\n \\nUnit \\n \\nTopic \\n \\nPage no \\n1 III Bayesian learning-Introduction ,Bayes \\nTheorem & Concept Learning maximum \\n36 \\n2 III Maximum Likelihood Hypotheses for Predicting \\nProbabilities(MAP) \\n42 \\n3 III Gibs Algorithm, Naïve Bayes Classifier 46 \\n4 III Minimum Description Length Principle , Bayes \\nOptimal Classifier \\n47 \\n \\n5 III An Example: Learning to Classify Text, Bayesian \\nBelief Networks \\n \\n50 \\n \\n6 III EM Algorithm. Instance-Based Learning-Introduction 51 \\n7 III k-Nearest Neighbor Learning, Locally Weighted \\nRegression 55 \\n8 III Radial Basis Functions, Case-Based Reasoning 56 \\n9 III Remarks on Lazy and Eager Learning. 57 \\nMALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='74d771c6-4bd4-4881-802d-4dfb08dba1f4', embedding=None, metadata={'page_label': '6', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='6  \\n \\n \\n \\nS. No \\n \\nUnit Topic Page no \\n1 IV Pattern Comparison Techniques-Temporal patterns, 58 \\n \\n2 IV  \\nDynamic Time Warping Methods \\n \\n61 \\n3 IV Clustering 67 \\n5 IV K-means clustering 69 \\n6 IV K-Mode Clustering. Codebook Generation 70 \\n7 IV Vector Quantization. 76 \\n \\n \\n \\n \\n \\n \\n \\nS. No \\n \\nUnit \\n \\nTopic \\n \\nPage no \\n \\n1 V Genetic Algorithms: Different search methods \\nfor induction \\n \\n78 \\n \\n2 V  \\nExplanation-based Learning: using prior knowledge to \\nreduce sample complexity. \\n \\n79 \\n \\n3 V Dimensionality reduction \\n \\n82 \\n \\n4 V  \\nPrincipal component analysis \\n \\n84 \\n \\n5 \\n \\nV \\n \\nLinear discriminate analysis, factor analysis, \\n \\n85 \\n \\n6 V \\nIndependent component analysis: multidimensional \\nscaling, and manifold learning. \\n \\n86 \\nMALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='352a1852-94a5-45a5-8e45-19ebaad20a03', embedding=None, metadata={'page_label': '7', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n1 \\n \\n \\n \\n \\nUNIT-I \\n \\n \\nMachine Learning \\nis the  field of study that gives  computers the capability to learn without  \\nbeing explicitly programmed. ML is one of the most exciting technologies  \\nthat one would have ever  come across. As it is  evident from the name,  it \\ngives the computer that makes it more similar to humans: The ability to  \\nlearn. Machine learning is actively being used today, perhaps in many more  \\nplaces than one would expect. \\n \\nMachine Learning is broadly categorized under the following headings: \\n \\n \\nMachine learning evolved from left to right as shown in the above diagram. \\n• Initially, researchers started out with Supervised Learning. This is the \\ncase of housing price prediction discussed earlier \\n. • This was followed by unsupervised learning, where the machine is made \\nto learn on its own without any supervision. \\n• Scientists discovered further that it may be a good idea to reward the  \\nmachine when it does the job the expected way and there came the \\nReinforcement Learning. \\n• Very soon, the data that is available these days has become so humongous  \\nthat the conventional techniques developed so far failed to analyse the big  \\ndata and provide us the predictions. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b0eebf5a-49da-4e8c-a6b0-011f5fc68d52', embedding=None, metadata={'page_label': '8', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n2 \\n \\n \\n \\n \\n \\n \\n \\n• Thus, came the deep learning where the human brain is simulated in the  \\nArtificial Neural Networks (ANN) created in our binary computers. \\n• The machine now learns on its own using the high computing power and  \\nhuge memory resources that are available today. \\n• It is now observed that Deep Learning has solved many of the previously  \\nunsolvable problems. \\n• The technique is now further advanced by giving incentives to Deep  \\nLearning networks as awards and there finally comes Deep Reinforcement  \\nLearning. \\nLet us now study each of these categories in more details \\nSupervised Learning: \\nSupervised learning is analogous to training a child to walk. You will hold \\nthe child’s hand, show him how to take his foot forward, walk yourself for a  \\ndemonstration and so on, until the child learns to walk on his own. \\nRegression: \\nSimilarly, in the case of supervised learning, you give concrete known \\nexamples to the computer. You say that for given feature value x1 the output  \\nis y1, for x2 it is y2, for x3 it is y3, and so on. Based on this data, you let the  \\ncomputer figure out an empirical relationship between x and y. Once the  \\nmachine is trained in this way with a sufficient number of data points, now  \\nyou would ask the machi ne to predict Y for a given X. Assuming that you  \\nknow the real value of Y for this given X, you will be able to deduce whether  \\nthe machine’s prediction is correct. Thus, you will test whether the machine  \\nhas learned by using the known test data. Once you are satisfied that the  \\nmachine is able to do the predictions with a desired level of accuracy (say 80  \\nto 90%) you can stop further training the machine. Now, you can safely use  \\nthe machine to do the predictions on unknown data points, or ask the \\nmachine to predict Y for a given X for which you do not know the real value  \\nof Y. This training comes under the regression that we talked about earlier. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2b94c9e5-5ed2-419d-80f3-b1b2b4be4d65', embedding=None, metadata={'page_label': '9', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n3 \\n \\n \\n \\nClassification: \\nYou may also use machine learning techniques for classification problems. In \\nclassification problems, you classify objects of similar nature into a single  \\ngroup. For example, in a set of 100 students say, you may like to group them  \\ninto three groups based on their heights - short, medium and long. Measuring \\nthe height of each student, you will place them in a proper group. Now, when  \\na new student comes in, you will put him in an appropriate group by \\nmeasuring his height. By following the principles in regression training, you  \\nwill train the machine  to classify a student based on his feature – the height. \\nWhen the machine learns how the groups are formed, it will be able to  \\nclassify any unknown new student correctly. Once again, you would use the  \\ntest data to verify that the machine has learned your technique of \\nclassification before putting the developed model in production. Supervised  \\nLearning is where the AI really began its journey. This technique was \\napplied successfully in several cases. You have used this model while doing  \\nthe hand-written recognition on your machine. Several algorithms have been  \\ndeveloped for supervised learning. You will learn about them in the \\nfollowing chapters. \\nUnsupervised Learning: \\nIn unsupervised learning, we do not specify a target variable to the machine,  \\nrather we ask  machine “What can you tell me about X?”. More specifically,  \\nwe may ask questions such as given a huge data set X, “What are the five \\nbest groups we can make out of X?” or “What features occur together most  \\nfrequently in X?”. To arrive at the answers to such questions, you can \\nunderstand that the number of data points that the machine would require to  \\ndeduce a strategy would be very large. In case of supervised learning, the  \\nmachine can be trained with even about few thousands of data points. \\nHowever, in case of unsupervised learning, the number of data points that is  \\nreasonably accepted for learning starts in a few millions. These days, the data  \\nis generally abundantly available. The data ideally requires curating. \\nHowever, the amount of data that is cont inuously flowing in a social area  \\nnetwork, in most cases data curation is an impossible task. The following  \\nfigure shows the boundary between the yellow and red dots as determined by  \\nunsupervised machine learning. You  can see it clearly  that the machine ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7f30c2f1-4d6c-40e7-a7a4-3cb539a757fa', embedding=None, metadata={'page_label': '10', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n4 \\n \\n \\n \\nwould be able to determine the class of each of the black dots with a fairly  \\ngood accuracy. \\n \\n \\nReinforcement Learning: \\nConsider training a pet dog, we train our pet to bring a ball to us. We throw  \\nthe ball at a certain distance and ask the dog to fetch it back to us. Every time  \\nthe dog does this right, we reward the dog. Slowly, the dog learns that doing  \\nthe job rightly gives him a reward and then the dog starts doing the job right  \\nway every time in future. Exactly, this concept is applied in “Reinforcement”  \\ntype of learning. The technique was initially developed for machines to play  \\ngames. The machine is given an algorithm to analyse all possible moves at  \\neach stage of the game. The machine may select one of the moves at random.  \\nIf the move is right, the machine is rewarded, otherwise it may be penalized.  \\nSlowly, the machine will start differentiating between right and wrong moves  \\nand after several iterations would learn to solve the game puzzle with a better  \\naccuracy. The accuracy of winning the game would improve as the machine  \\nplays more and more games. \\nThe entire process may be depicted in the following diagram: \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='27f4c5da-9008-4924-affd-625e627572a2', embedding=None, metadata={'page_label': '11', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n5 \\n \\n \\n \\n \\n \\n \\nDeep Learning: \\nThe deep learning is a model based on Artificial Neural Networks (ANN),  \\nmore specifically Convolutional Neural Networks (CNN)s. There are several  \\narchitectures used in deep learning such as deep neural n etworks, deep belief  \\nnetworks, recurrent neural networks, and convolutional neural networks. \\nThese networks have been successfully applied in solving the problems of  \\ncomputer vision, speech recognition, natural language processing, \\nbioinformatics, drug des ign, medical image analysis, and games. There are  \\nseveral other fields in which deep learning is proactively applied. The deep  \\nlearning requires huge processing power and humongous data, which is \\ngenerally easily available these days. We will talk about deep learning more  \\nin detail in the coming chapters. \\nDeep Reinforcement Learning: \\nThe Deep Reinforcement Learning (DRL) combines the techniques of both  \\ndeep and reinforcement learning. The reinforcement learning algorithms like  \\nQ learning are now combined with deep learning to create a powerful DRL  \\nmodel. The technique has been with a great success in the fields of robotics,  \\nvideo games, finance and healthcare. Many previously unsolvable problems  \\nare now solved by creating DRL models. There is lots of research going on \\nin this area and this is very actively pursued by the industries. So far, you \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e8ab80cd-ad86-4c1a-bc16-cc26bdeeac63', embedding=None, metadata={'page_label': '12', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n6 \\n \\n \\n \\nhave got a brief introduction to various machine learning models, now let us  \\nexplore slightly deeper into various algorithms that are available under these  \\nmodels. \\nWell posed learning problems: \\n \\nA computer program is said to learn from experience E in context to some  \\ntask T and some performance measure P, if its performance on T, as was  \\nmeasured by P, upgrades with experience E. \\nAny problem can be segregated as well -posed learning problem if it has three  \\ntraits – \\n• Task \\n• Performance Measure \\n• Experience \\nCertain example that efficiently defines the well-posed learning problems \\nare: \\n \\n1. To better filter emails as spam or not \\n• Task – Classifying emails as spam or not \\n• Performance Measure – The fraction of emails accurately classified as spam \\nor not spam \\n• Experience – Observing you label emails as spam or not spam \\n2. A checkers learning problem \\n• Task – Playing checkers game \\n• Performance Measure – percent of games won against opposer \\n• Experience – playing implementation games against itself \\n3. Handwriting Recognition Problem \\n• Task – Acknowledging handwritten words within portrayal \\n• Performance Measure – percent of words accurately classified \\n• Experience – a directory of handwritten words with given classifications \\n4. A Robot Driving Problem \\n• Task – driving on public four-lane highways using sight scanners \\n• Performance Measure – average distance progressed before a fallacy \\n• Experience – order of images and steering instructions noted down while \\nobserving a human driver \\n5. Fruit Prediction Problem ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='27b495fe-62af-479c-a728-ee8ffc4d7804', embedding=None, metadata={'page_label': '13', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Department of CSE MRCET \\n7 \\n \\n \\n \\n• Task – forecasting different fruits for recognition \\n• Performance Measure – able to predict maximum variety of fruits \\n• Experience – training machine with the largest datasets of fruits images \\n \\n6. Face Recognition Problem \\n• Task – predicting different types of faces \\n• Performance Measure – able to predict maximum types of faces \\n• Experience – training machine with maximum amount of datasets of \\ndifferent face images \\n7. Automatic Translation of documents \\n• Task – translating one type of language used in a document to other language \\n• Performance Measure – able to convert one language to other efficiently \\n• Experience – training machine with a large dataset of different types of \\nlanguages \\n \\nDesign of a learning system: \\n \\nJust now we looked into the learning process and also understood the goal  \\nof the learning. When we want to design a learning system that follows the \\nlearning process, we need to consider a few design choices. The design  \\nchoices will be to decide the following key components: \\n1. Type of training experience \\n2. Choosing the Target Function \\n3. Choosing a representation for the Target Function \\n4. Choosing an approximation algorithm for the Target Function \\n5. The final Design \\nWe will look into the game - checkers learning problem and apply the above \\ndesign choices. For a checkers learning problem, the three elements will be, \\n• Task T: To play checkers \\n• Performance measure P: Total present of the game won in the tournament. \\n• Training experience E: A set of games played against itself. \\n \\nType of training experience: \\nDuring the  design of the checker's learning system, the type of  training \\nexperience available for a learning system will have a significant effect on \\nthe success or failure of the learning. \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b27e3b26-9601-44ca-b998-461df9ef5b97', embedding=None, metadata={'page_label': '14', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n8 \\n \\n \\n \\nDirect or Indirect training experience: \\nIn the case of direct training experience, an individual board states and \\ncorrect move for each board state are given. In case of indirect training  \\nexperience, the move sequences for a game and the final result (win, lose or  \\ndraw) are given for a number of games. How to assign credit or blame to  \\nindividual moves is the credit assignment problem. \\n \\n1. Teacher or Not: \\n\\uf0a2 Supervised: \\nThe training experience will be labelled, which means, all the board states  \\nwill be labelled with the correct move. So the learning takes place in the  \\npresence of a supervisor or a teacher. \\n\\uf0a2 Un-Supervised: \\nThe training experience will be unlabelled, which means, all the board \\nstates will not have the moves. So the learner generates random games and  \\nplays against itself with no supervision or teacher involvement. \\n \\n\\uf0a2 Semi-supervised: \\nLearner generates game states and asks the teacher for help in finding \\nthe correct move if the board state is confusing. \\n2. Is the training experience good: \\n \\n\\uf0a2 Do the  training examples represent the distribution of  examples over  \\nwhich the final system performance will be measured? Pe rformance is best  \\nwhen training examples and test examples are from the same/a similar \\ndistribution. \\n\\uf0a2 The checker player learns by playing against oneself. Its experience is  \\nindirect. It may not encounter moves that are common in human expert play.  \\nOnce the proper training experience is available, the next design step will be  \\nchoosing the Target Function. \\nChoosing the Target Function: \\nWhen you are playing the checkers game, at any moment of time, you make \\na decision on choosing the best move from different possibilities. You think  \\nand apply the learning that you have gained from the experience. Here the  \\nlearning is, for a specific board, you move a checker such that your board ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='43ca986f-dd78-49f2-9e10-f352ce1429ed', embedding=None, metadata={'page_label': '15', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n9 \\n \\n \\n \\nstate tends towards the winning situation. Now the same learning has to be  \\ndefined in terms of the target function. \\nHere there are 2 considerations — direct and indirect experience. \\n• During the direct experience the checkers learning system, it needs only  \\nto learn how to choose the best move among some large search space. We  \\nneed to find a target function that will help us choose the best move among  \\nalternatives. \\nLet us call this function Choose Move and use the notation Choose Move: B \\n→M to indicate that this function accepts as  input any board from the set of  \\nlegal board states B and produces as output some move from the set of legal  \\nmoves M. \\n• When there is an indirect experience it becomes difficult to learn such  \\nfunction. How about assigning a real score to the board state. \\n \\n \\nSo the function be V: B →R indicating that this accepts as input any board  \\nfrom the set of legal board states B and produces an output a real score. This  \\nfunction assigns the higher scores to better board states \\n \\n \\n \\n \\nIf the system can successfully learn such a target function V, then it can \\neasily use it to select the best move from any board position. \\nLet us therefore define the target value V(b) for an arbitrary board state b in  \\nB, as follows: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5a1ae0c7-03af-4564-90be-4463489466a9', embedding=None, metadata={'page_label': '16', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n10 \\n \\n \\n \\n1. if b is a final board state that is won, then V(b) = 100 \\n2. if b is a final board state that is lost, then V(b) = -100 \\n3. if b is a final board state that is drawn, then V(b) = 0 \\n4. if b is a not a final state in the game, then V (b) = V (b’), where b’ is the best  \\nfinal board state that can be achieved starting from b and playing optimally  \\nuntil the end of the game. \\nThe (4) is a recursive definition and to determine the value of V(b) for a  \\nparticular board state, it performs the search ahead for the optimal line of  \\nplay, all the way to the end of the game. So this definition is not efficiently  \\ncomputable by our checkers playing program, we say that it is a non- \\noperational definition. \\n \\n \\nChoosing a representation for the Target Function: \\nNow that we have specified the ideal target function V, we must choose a  \\nrepresentation that the learning program will use to describe the function ^V  \\nthat it will learn. As with earlier design choices, we again have many options.  \\nWe could, for example, allow the program to represent us ing a large table  \\nwith a distinct entry specifying the value for each distinct board state. Or we  \\ncould allow it to represent using a collection of rules that match against  \\nfeatures of the board state, or a quadratic polynomial function of predefined  \\nboard features, or an artificial neural network. In general, this choice of  \\nrepresentation involves a crucial trade off. On one hand, we wish to pick a  \\nvery expressive representation to allow representing as close an \\napproximation as possible to the ideal target function V. \\nOn the other hand, the more expressive the representation, the more training  \\ndata the program will require in order to choose among the alternative \\nhypotheses it can represent. To keep the discussion brief, let us choose a  \\nsimple represe ntation: for any given board state, the function ^V will be  \\ncalculated as a linear combination of the following board features: \\n• x1(b) — number of black pieces on board b \\n• x2(b) — number of red pieces on b \\n• x3(b) — number of black kings on b ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='68383fc1-7b0c-490f-9b21-be63ca8cbfd5', embedding=None, metadata={'page_label': '17', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n11 \\n \\n \\n \\n• x4(b) — number of red kings on b \\n• x5(b) — number of red pieces threatened by black  • x6(b) — number of  \\nblack pieces threatened by red \\n^V = w0 + w1 · x1(b) + w2 · x2(b) + w3 · x3(b) + w4 · x4(b) +w5 · x5(b) + w6 · x6(b) \\n \\n \\nWhere w0 through w6 are  numerical coefficients or weights to be obtained  \\nby a learning algorithm. Weights w1 to w6 will determine the relative \\nimportance of different board features. \\nSpecification of the Machine Learning Problem at thi s time: Till now we \\nworked on choosing the type of training experience, choosing the target  \\nfunction and its representation. The checkers learning task can be \\nsummarized as below. \\n• Task T: Play Checkers \\n• Performance Measure: % of games won in world tournament \\n• Training Experience E: opportunity to play against itself \\n• Target Function: V: Board → R \\n• Target Function Representation: ^V = w0 + w1 · x1(b) + w2 · x2(b) + w3 ·  \\nx3(b) + w4 · x4(b) +w5 · x5(b) + w6 · x6(b) \\nThe first three items above correspond to the specification of the learning  \\ntask, where as the final two items constitute design choices for the \\nimplementation of the learning program. \\n \\n \\n \\n \\nChoosing an approximation algorithm for the Target Function: \\nGenerating training data — To train our learning program, we need a set of  \\ntraining data, each describing a specific board state b and the training value  \\nV_train (b) for b. Each training example is an ordered pair <b,v_train(b)>. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ab46b749-7e4f-4914-8d52-76bbcf741a80', embedding=None, metadata={'page_label': '18', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n12 \\n \\n \\n \\nTemporal difference (TD) learning is a concept central to reinforcement \\nlearning, in which learning happens through the iterative correction of your  \\nestimated returns towards a more accurate target return. \\n\\uf056 V_train(b) ← ^V(Successor(b)) \\n \\nFinal Design for Checkers Learning system: \\nThe final design of our checkers learning system can be naturally described  \\nby four distinct program modules that represent the central components in  \\nmany learning systems. \\n1. The performance System: Takes a new board as input and outputs a trace of \\nthe game it played against itself. \\n2. The Critic: Takes the trace of a game as an input and outputs a set of training  \\nexamples of the target function. \\n3. The Generalizer: Takes training examples as input and outputs a hypothesis  \\nthat estimates the target function. Good generalization to new cases is \\ncrucial. \\n4. The Experiment Generator: Takes the current hypothesis (currently learned  \\nfunction) as input and outputs a new problem (an initial board state) for the  \\nperformance system to explore. \\n \\n \\n \\nIssues in Machine Learning: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='160ed4f8-9560-4773-b3e8-587797e4f014', embedding=None, metadata={'page_label': '19', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Department of CSE MRCET \\n13 \\n \\n \\n \\nOur checkers example raises a number of generic questions about machine  \\nlearning. The field of machine learning, and much of this book, is concerned  \\nwith answering questions such as the following: \\n• What algorithms exist for learning general target functions from specific  \\ntraining examples? In what settings will particular algorithms converge to the  \\ndesired function, given sufficient training data? Which algorithms perform  \\nbest for which types of problems and representations? \\n• How much training data is sufficient? What general bounds can be found to  \\nrelate the confidence in learned hypotheses to the amount of training \\nexperience and the character of the learner's hypothesis space? \\n• When and how can prior knowledge held by the learner guide the process of  \\ngeneralizing from examples? Can prior knowledge be helpful even when it is  \\nonly approximately correct? \\n• What is the best strategy for choosing a useful next training experience, and  \\nhow does the choice of this strategy alter the complexity of the learning  \\nproblem? \\n• What is the best way to reduce the learning task to one or more function  \\napproximation problems? Put another way, what specific functions should \\nthe system attempt to learn? Can this process itself be automated? \\n• How can the learner automatically alter its representation to improve its  \\nability to represent and learn the target function? \\nCONCEPT LEARNING: \\n \\n• Inducing general functions from specific training examples is a main issu e of \\nmachine learning. \\n• Concept Learning: Acquiring  the definition  of a general category  from \\ngiven sample positive and negative training examples of the category. \\n• Concept Learning can see as a problem of searching through a predefined  \\nspace of potential hypotheses for the hypothesis that best fits the training  \\nexamples. \\n• The hypothesis space has a general -to-specific ordering of hypotheses, and  \\nthe search can be efficiently organized by taking advantage of a naturally  \\noccurring structure over the hypothesis space. \\nA Formal Definition for Concept Learning: \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='aaa10151-2f8e-4630-bba5-4e29bbfff69a', embedding=None, metadata={'page_label': '20', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n14 \\n \\n \\n \\nInferring a Boolean-valued function from training examples of its input and  \\noutput. \\n• An example for concept -learning is the learning of bird -concept from the  \\ngiven examples of birds (positive examples) and non-birds (negative \\nexamples). \\n• We are trying to learn the definition of a concept from given examples.  \\nA Concept Learning Task: Enjoy Sport Training Examples \\n \\n \\nA set of example days, and each is described by six attributes.  The task is to  \\nlearn to predict the value of Enjoy Sport for arbitrary day, based on the \\nvalues of its attribute values. \\n \\n \\nConcept Learning as Search: \\n• Concept learning can be viewed as the task  of searching  through a large  \\nspace of hypotheses implicitly defined by the hypothesis representation. \\n• The goal of this search is to find the hypothesis that best fits the training  \\nexamples. \\n• By selecting a hypothesis representation, the designer of the learning \\nalgorithm implicitly def ines the space of all hypotheses that the program can  \\never represent and therefore can ever learn. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c808a289-8d5f-4b31-865b-3b675370832b', embedding=None, metadata={'page_label': '21', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n15 \\n \\n \\n \\nFIND-S: \\n• FIND-S Algorithm starts from the most specific hypothesis and generalize it  \\nby considering only positive examples. \\n• FIND-S algorithm ignores negative example \\n: As long as the hypothesis space contains a hypothesis that  describes the  \\ntrue target concept, and the training data contains no errors, ignoring \\nnegative examples does not cause to any problem. \\n• FIND-S algorithm finds the most specific hypothesis within H that is \\nconsistent with the positive training examples. – The final hypothesis will  \\nalso be consistent with negative examples if  the correct target concept is in  \\nH, and the training examples are correct. \\nFIND-S Algorithm: \\n1. Initialize h to the most specific hypothesis in H \\n2. For each positive training instance x For each attribute \\nconstraint a, in h \\nIf the constraint a, is satisfied by x \\nThen do nothing \\n3. Else replace a, in h by the next more general constraint that is satisfied by \\nx 4. Output hypothesis h \\nFIND-S Algorithm – Example: \\nImportant-Representation: \\n \\n1. ? indicates that any value is acceptable for the attribute. \\n2. specify a single required value (e.g., Cold) for the attribute. \\n3. Φ indicates that no value is acceptable. \\n4. The most general hypothesis is represented by: {?, ?, ?, ?, ?, ?} \\n5. The most specific hypothesis is represented by: {ϕ, ϕ, ϕ, ϕ, ϕ, ϕ} \\n \\nSteps Involved in Find-S: \\n1. Start with the most specific hypothesis. h = {ϕ, ϕ, ϕ, ϕ, ϕ, ϕ} ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='55c67ece-467c-452e-aa55-d55e5f3f372d', embedding=None, metadata={'page_label': '22', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n16 \\n \\n \\n \\n2. Take the next example and if it is negative, then no changes occur to the \\nhypothesis. \\n3. If the example is positive and we find that our initial hypothesis is too \\nspecific then we update our current hypothesis to a general condition. \\n4. Keep repeating the above steps till all the training examples are complete. \\n5. After we have completed all the training examples we will have the final  \\nhypothesis when can use to classify the new examples. Example: Consider \\nthe following data set having the data about which particular seeds are \\npoisonous. \\n \\n \\n \\nFirst, we consider the hypothesis to be a more specific hypothesis. Hence,  \\nour hypothesis would be: h = {ϕ, ϕ, ϕ, ϕ, ϕ, ϕ} \\n \\n \\nConsider example 1: \\nThe data in example 1 is {GREEN, HARD, NO, WRINKLED}. We see that  \\nour initial hypothesis is more specific and we have to generalize it for this  \\nexample. \\nHence, the hypothesis becomes: \\nh = {GREEN, HARD, NO, WRINKLED} \\nConsider example 2: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8e70d546-75b5-4b32-8621-c882c43e1863', embedding=None, metadata={'page_label': '23', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n17 \\n \\n \\n \\nHere we see that this example has a negative outcome. Hence we neglect  \\nthis example and our hypothesis remains the same. h = {GREEN, \\nHARD, NO, WRINKLED} \\nConsider example 3: \\nHere we see that this example has a negative outcome. hence we neglect  \\nthis example and our hypothesis remains the same. h = {GREEN, \\nHARD, NO, WRINKLED} \\nConsider example 4: \\nThe data present in example 4 is {ORANGE, HARD, NO, WRINKLED}. \\nWe \\ncompare every single attribute with the  initial data and if any mismatch is  \\nfound we replace that particular attribute with a general case (“ ?”). After  \\ndoing the process the hypothesis becomes: h = {?, HARD, NO, \\nWRINKLED } \\nConsider example 5: \\nThe data present in example 5 is {GREEN, SOFT, YES,  SMOOTH}. We \\ncompare every single attribute with the initial data and if any mismatch is  \\nfound we replace that particular attribute with a general case ( “?” ). After  \\ndoing the process the hypothesis becomes: \\nh = {?, ?, ?, ? } \\nSince we have reached a point where all the attributes in our hypothesis \\nhave the general condition, example 6 and example 7 would result in the  \\nsame hypothesizes with all general attributes. h = {?, ?, ?, ? } \\nHence, for the given data the final hypothesis would be: \\nFinal Hypothesis: h = { ?, ?, ?, ? }. \\n \\nVersion Spaces \\nDefinition(Version space). A concept is complete if it covers all positive  \\nexamples. \\nA concept is consistent if it covers none of the negative examples. The  \\nversion space is the set of all complete and consistent concepts. This set is  \\nconvex and is fully defined by its least and most general elements. \\nCandidate-Elimination Learning Algorithm ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ba3e4e31-efee-42dc-a4f9-eb256fc82da5', embedding=None, metadata={'page_label': '24', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n18 \\n \\n \\n \\nThe CANDIDATE-ELIMINTION algorithm computes the version space \\ncontaining all hypotheses from H that are consistent with an observed \\nsequence of training examples. \\nInitialize G to the set of maximally general hypotheses in H Initialize S to \\nthe set of maximally specific hypotheses in H For each training example d, \\ndo \\n• If d is a positive example \\n• Remove from G any hypothesis inconsistent with d \\n• For each hypothesis s in S that is not consistent with d \\n• Remove s from S • Add to S all minimal generalizations h of s such that h is \\nconsistent with d, and some member of G is more general than h \\n• Remove from S any hypothesis that is more general than another hypothesis \\nin S \\n• If d is a negative example \\n• Remove from S any hypothesis inconsistent with d \\n• For each hypothesis g in G that is not consistent with d \\n• Remove g from G 18\\\\ \\n• Add to G all minimal specializations h of g such that \\n• h is consistent with d, and some member of S is more specific than h \\n• Remove from G any hypothesis that is less general than another hypothesis \\nin G. \\nCANDIDATE- ELIMINTION algorithm using version spaces An \\nIllustrative Example: \\n ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4e0f3450-979b-4926-b7cd-5fd6086a3601', embedding=None, metadata={'page_label': '25', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n19 \\n \\n \\n \\nCANDIDATE-ELIMINTION algorithm begins by initializing the version \\nspace to the set of all hypotheses in H; \\nboundary set to contain the most general hypothesis in H,  G0 ?, ?, ?, ?, ?, \\nWhen the first training example is presented, the \\nCANDIDATEELIMINTION algorithm checks the S boundary and finds that \\nit is overly specific and it fails to cover the positive example. \\n• The boundary is therefore revised by moving it to the least more general \\nhypothesis that covers this new example. \\n• No update of the G boundary is needed in response to this training example \\nbecause Go correctly covers this example. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• When the second training example is observed, it has a similar effect of \\ngeneralizing S further to S2, leaving G again unchanged i.e., G2 = G1 =G0 \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='19cfc674-6188-42c7-a316-f0d58bf59fbc', embedding=None, metadata={'page_label': '26', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n20 \\n \\n \\n \\n• Consider the third training example. This negative example reveals that the  \\nboundary of the version space is overly general, that is, the hypothesis in G  \\nincorrectly predicts that this new example is a positive example. \\n• The hypothesis in the G boundary  must therefore be specialized  until it  \\ncorrectly classifies this new negative example. \\n \\n \\n \\n \\nGiven that there are six attributes that could be specified to  specialize G2,  \\nwhy are there only three new hypotheses in G3? \\n \\nFor example, the hypothesis h = (?, ?, Normal, ?, ?, ?) is a minimal \\nspecialization of G2 that correctly labels the new example as a negative  \\nexample, but it is not included in G3. The reason this hypothesis is excluded  \\nis that it is inconsistent with the previously encountered positive examples.  \\nConsider the fourth training example. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='1b920bde-bb9c-4fcf-8197-61a61f40a543', embedding=None, metadata={'page_label': '27', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n21 \\n \\n \\n \\n \\n \\n• This positive example  further generalizes  the S boundary of  the version  \\nspace. It also results in removing one member of the  G boundary, because  \\nthis member fails to cover the new positive example After processing these  \\nfour examples, the boundary sets S4 and G4 delimit the version space of all  \\nhypotheses consistent with the set of incrementally observed training \\nexamples. \\n• After processing these four examples, the boundary sets S4 and G4 delimit  \\nthe version space of all hypotheses consistent with the set of incrementally  \\nobserved training examples. \\n \\n \\n \\nInductive bias: \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='cf49f5e4-cd71-4f2a-94c3-359aee87ea57', embedding=None, metadata={'page_label': '28', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n \\n \\nDecision Tre:e Decision Trees are a type of Supervised Machine Learning (that \\nis you explain what the input is and what the corresponding output is in the \\ntraining data) where th e data is continuously split according to a certain \\nparameter. The tree can be explained by two entities, namely decision nodes and  \\nleaves. The leaves are the decisions or the final outcomes. And the decision nodes \\nare where the data is split. \\n \\nDecision Tree Representation: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAn example of a decision tree can be explained using above binary tree. Let’s say  \\nyou want to predict whether a person is fit given their information like age, eating \\nhabit, and physical activity, etc. The decision nodes here are questions like \\n‘What’s the age?’, ‘Does he exercise?’, and ‘Does he eat a lot of pizzas’? And the \\nleaves, which are outcomes like either ‘fit’, or ‘unfit’. In this case this was a \\nbinary classification problem (a yes no type problem). There are two main types \\nof Decision Trees: \\n \\n1. Classification trees (Yes/No types): \\n \\nWhat we have seen above is an example of classification tree, where the \\noutcome was a variable like ‘fit’ or ‘unfit’. Here the decision variable is \\nCategorical. \\nInductive bias refers to the restriction2s2 that are imposed by the assumptions \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f97038d0-4e52-4daa-87d1-ef87bdd8a9f7', embedding=None, metadata={'page_label': '29', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n23 \\n \\n \\n \\nHere the decision or the outcome variable is Continuous, e.g. a number like \\n123. Working Now that we know what a Decision Tree is, we’ll see how it  \\nworks internally. There are many algorithms out there which construct \\nDecision Trees, but one  of the best is called as ID3 Algorithm. ID3  Stands \\nfor Iterative Dichotomiser3. \\n \\nBefore discussing the ID3 algorithm, we’ll go through few definitions. \\nEntropy, also called as Shannon Entropy is denoted by H(S) for a finite set S,  \\nis the measure of the amount of uncertainty or randomness in data. \\n \\nAppropriate Problems for Decision Tree Learning: \\n• Instances are represented by attribute-value pair \\n• The target function has discrete output values \\n• Disjunctive descriptions may be required \\n• The training data may contain errors \\n• The training data may contain missing attribute values. \\n• Suitable for classifications. \\n \\nHypothesis Space Search: \\n \\nThe set of possible decision tree, Simple to complex, hill climbing search. \\nCapability: \\n• Hypothesis space of all decision trees is a complete space of finite discrete \\nvalued functions. \\n \\n• ID3 maintains only a single current hypothesis. \\n \\n• Cannot determine how many alternative decision trees are consistent with \\nthe available training data. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4470bf85-dafb-4c69-a6dd-ac2314aca426', embedding=None, metadata={'page_label': '30', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n24 \\n \\n \\n \\n• ID3 uses all training example at each step to make statistically based \\ndecisions regarding how to refine its current hypothesis. \\n \\n• The resulting search is much less sensitive to errors in individual training \\nexamples. \\n \\n \\n \\n \\nInductive Bias in Decision Tree Learning: Note H is the power set of \\ninstances X \\n \\n• Inductive Bias in ID3 – Approximate inductive bias of ID3 \\n \\n\\uf0a2 Shorter trees are preferred over larger tress \\n \\n\\uf0a2 BFS-ID3 \\n \\nDifference between (ID3 & C-E) && Restriction bias and Preference \\nbias \\nID3 Candidate-Elimination \\nSearches a complete hypothesis space \\nincompletely \\nSearches an incomplete hypothesis \\nspace completely \\nInductive bias is solely a consequence \\nof the ordering of hypotheses by its \\nsearch strategy \\nInductive bias is solely a \\nconsequence of the expressive \\npower of its hypothesis \\nrepresentation \\nsss \\nRestriction bias Preference bias \\nCandidate-Elimination ID3 \\nCategorical restriction on the set of \\nhypotheses considered \\nPreference for certain hypotheses \\nover others ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='96d8573c-fea6-4a57-90ec-85fd2732f609', embedding=None, metadata={'page_label': '31', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n25 \\n \\n \\n \\nPossibility of excluding the unknown \\ntarget function \\nWork within a complete hypothesis \\nspace \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIssues in Decision Tree Learning: \\n \\n• Determine how deeply to grow the decision tree \\n• Handling continuous attributes \\n• Choosing an appropriate attribute selection measure \\n• Handling training data with missing attribute values \\n• Handling attributes with differing costs \\n• Improving computational efficiency ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='16147dee-3bd6-4531-afc1-596b0e26cc36', embedding=None, metadata={'page_label': '32', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n26 \\n \\n \\n \\nUNIT-II \\nArtificial Neural Networks \\nIntroduction: \\nArtificial Neural Networks (ANN) are algorithms based on brain function  \\nand are used to model complicated patterns and forecast issues. The Artificial  \\nNeural Network (ANN) is a deep learning method that arose from the \\nconcept of the human brain Biological Neural Networks. The development of  \\nANN was the result of an attempt to replicate the workings of the human  \\nbrain. The workings of ANN are extremely si milar to those of biological  \\nneural networks, although they are not identical. ANN  algorithm accepts \\nonly numeric and structured data. \\nThe ANN applications: \\nClassification, the aim is to predict the class of an input vector \\n• Pattern matching, the aim is to produce a pattern best associated with a given \\ninput vector. \\n• Pattern completion, the aim is to complete the missing parts of a given input \\nvector. \\n• Optimization, the aim is to find the optimal values of parameters in an \\noptimization problem. \\n• Control, an appropriate action is suggested based on given an input vectors \\n• Function approximation/times series modelling, the aim is to learn the \\nfunctional relationships between input and desired output vectors. \\n• Data mining, with the aim of discovering hidden patterns from data \\n(knowledge discovery). ANN architectures \\n• Neural Networks are known to be universal function approximators \\n• Various architectures are available to approximate any nonlinear function \\n• Different architectures allow for generation of functions of different \\ncomplexity and power \\n\\uf0a2 Feed forward networks \\n\\uf0a2 Feedback networks \\n\\uf0a2 Lateral networks ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e1643adc-acf1-46ec-8096-100afe0bb5ba', embedding=None, metadata={'page_label': '33', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n27 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAdvantages of Artificial Neural Networks \\nAttribute-value pairs are used to represent problems in ANN. \\n1. The output of ANNs  can be discrete-valued, real-valued, or a  vector of \\nmultiple real or discrete -valued characteristics, while the target function can  \\nbe discrete -valued, real -valued, or a vector of numerous real or discrete - \\nvalued attributes. \\n2. Noise in t he training data is not a problem for ANN learning techniques.  \\nThere may be mistakes in the training samples, but they will not affect the  \\nfinal result. \\n3. It’s utilized when a quick assessment of the taught target function is \\nnecessary. \\n4. The number of weights in the network. \\n5. the number of training instances evaluated, and the settings of different \\nlearning algorithm parameters can all contribute to extended training periods  \\nfor ANNs. \\nDisadvantages of Artificial Neural Networks \\n1. Hardware Dependence: \\n• The construction of Artificial Neural Networks necessitates the use of \\nparallel processors. \\n• As a result, the equipment’s realization is contingent. \\n2. Understanding the network’s operation: \\n• This is the most serious issue with ANN. \\n• When ANN provides a probing answer, it does not explain why or how it \\nwas chosen. \\n• As a result, the network’s confidence is eroded. \\n3. Assured network structure: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='3a6d01bb-d5cc-490f-865d-9d8e91810ee5', embedding=None, metadata={'page_label': '34', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n28 \\n \\n \\n \\n• Any precise rule does not determine the structure of artificial neural \\nnetworks. \\n• Experience and trial and error are used to develop a suitable network \\nstructure. \\n4. Difficulty in presenting the issue to the network: \\n• ANNs are capable of working with numerical data. \\n• Before being introduced to ANN, problems must be converted into \\nnumerical values. \\n• The display method that is chosen will have a direct impact on the network’s \\nperformance. \\n• The user’s skill is a factor here. \\n5. The network’s lifetime is unknown: • When the network’s error on the \\nsample is decreased to a specific amount, the training is complete. \\n• The value does not produce the best outcomes. \\nAppropriate Problems for Neural Network Learning: \\n1. Instances are represented by many attribute-value pairs (e.g., the pixels of a \\npicture. ALVINN [Mitchell, p. 84]). \\n2. The target function output may be discrete-valued, real-valued, or a vector of \\nseveral real- or discrete-valued attributes. \\n3. The training examples may contain errors. \\n4. Long training times are acceptable. \\n5. Fast evaluation of the learned target function may be required. \\n6. The ability for humans to understand the learned target function is not \\nimportant. \\nHistory of Neural Networks: \\n1. 1943: McCulloch and Pitts proposed a model of a neuron Perceptron (read \\n[Mitchell, section 4.4]) \\n2. 1960s: Widrow and Hoff explored Perceptron networks (which they called \\n“Adelines”) and the delta rule. \\n3. 1962: Rosenblatt proved the convergence of the perceptron training rule. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ca44a625-e08e-48b9-a719-92d22832a52d', embedding=None, metadata={'page_label': '35', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n29 \\n \\n \\n \\n4. 1969: Minsky and Papert showed that the Perceptron cannot deal with \\nnonlinearly-separable data sets ---even those that represent simple function  \\nsuch as X-OR. \\n5. 1970-1985: Very little research on Neural Nets \\n6. 1986: Invention of Backpropagation Rumelhart and McClelland, but also  \\nParker and earlier on: Werbos which can learn from nonlinearly -separable \\ndata sets. \\n7. Since 1985: A lot of research in Neural Nets! \\n \\n \\n \\n \\n \\n \\n \\nMultilayer Neural Network: \\n• A multiplayer perceptron is a feed forward neural network with one or more  \\nhidden layers \\n• The network consists of an input layer of source neurons, at least one hidden  \\nlayer of computational neurons, and an output layer of computational \\nneurons. \\n• The input signals are propagated in a forward direction on a layer -by-layer \\nbasis. \\n• Neurons in the hidden layer cannot be observed through input/output \\nbehaviour of the network. \\n• There is no obvious way to know what the desired output of the hidden layer  \\nshould be. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7c52f1e3-183f-42e1-82da-6508d3771f4c', embedding=None, metadata={'page_label': '36', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n30 \\n \\n \\n \\n \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d0a35079-49fd-4cfd-933e-9523c063c19b', embedding=None, metadata={'page_label': '37', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n31 \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e044d69b-79e4-4c01-ba8d-54dc9b2b5344', embedding=None, metadata={'page_label': '38', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n32 \\n \\n \\n \\nBack propagation: Overview \\n• Back propagation works by applying the gradient descent rule to a feed  \\nforward network. \\n• The algorithm is composed of two parts that get repeated over and over until  \\na pre-set maximal number of epochs, EP max. \\n• Part I, the feed forward pass: the activation v alues of the hidden and then  \\noutput units are computed. \\n• Part II, the back propagation pass: the weights of the network are updated - \\nstarting with the hidden to output weights and followed by the  input to \\nhidden weights--with respect to the sum of squares error and through a series  \\nof weight update rules called the Delta Rule. \\nDefinition: \\nThe Back propagation algorithm in neural network computes the gradient of  \\nthe loss function for a single weight by the chain rule. It efficiently computes  \\none layer at a t ime, unlike a native direct computation. It computes the  \\ngradient, but it does not define how the gradient is used. It generalizes the  \\ncomputation in the delta rule. \\nConsider the following Back propagation neural network example diagram to  \\nunderstand: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9fd76565-4838-47a2-b5d9-5456404e90ec', embedding=None, metadata={'page_label': '39', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n33 \\n \\n \\n \\n \\n• Inputs X, arrive through the preconnected path \\n• Input is modelled using real weights W. The weights are usually randomly \\nselected. \\n• Calculate the output for every neuron from the input layer, to the hidden \\nlayers, to the output layer. \\n• Calculate the error in the outputs \\nErrorB= Actual Output – Desired Output \\n• Travel back from the output layer to the hidden layer to adjust the weights \\nsuch that the error is decreased. \\n• Keep repeating the process until the desired output is achieved \\n \\n \\nWhy We Need Back propagation? \\n• Most prominent advantages of Back propagation are: \\n• Back propagation is fast, simple and easy to program \\n• It has no parameters to tune apart from the numbers of input \\n• It is a flexible method as it does not require prior knowledge about the \\nnetwork \\n• It is a standard method that generally works well \\n• It does not need any special mention of the features of the function to be \\nlearned. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n1. Inputs X, arrive through the preconnected path \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fabeec9d-2338-40e0-a225-fefcce99d653', embedding=None, metadata={'page_label': '40', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n34 \\n \\n \\n \\nTypes of Back propagation Networks \\nTwo Types of Back propagation Networks are: \\n• Static Back-propagation \\n• Recurrent Back propagation Static back-propagation: \\nIt is one kind of back propagation network which produces a mapping of a  \\nstatic input for static output. It is useful to solve static classification issues  \\nlike optical character recognition. \\nRecurrent Back propagation: \\nRecurrent Back propagation in data mining is fed forward until a fixed value  \\nis achieved. After that, the error is computed and propagated backward. \\n \\nDisadvantages of using Back propagation \\n• The actual performance of back propagation on a specific problem is \\ndependent on the input data. \\n• Back propagation algorithm in data mining can be quite sensitive to noisy \\ndata \\n• You need to use the matrix-based approach for back propagation instead of \\nmini-batch. \\n \\n \\nBack propagation: The Algorithm \\n• Initialize the weights to small random values; create a random pool of all the \\ntraining patterns; set EP, the number of epochs of training to 0. \\n• 2. Pick a training pattern from the remaining pool of patterns and propagate \\nit forward through the network. \\n• 3. Compute the deltas, k for the output layer. \\n• 4. Compute the deltas, \\nbackward. \\nfor the hidden  layer by propagating  the error \\n• Update all the connections such that \\n• W Newji = wjiold + wji and w Newkj = wkjOld + wkj \\nj ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c8c33d70-c371-4585-a2a8-0976f30df25d', embedding=None, metadata={'page_label': '41', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n35 \\n \\n \\n \\n• If any pattern remains in the pool, then  go back to Step 2. If all the training  \\npatterns in the pool have been used, then set EP = EP+1, and if EP  EPMax, \\nthen create a random pool of patterns and go to Step 2. If EP = EPMax, then  \\nstop. \\n \\nBack propagation: The Momentum: \\n• To this point, Back propagation has the disadvantage of being too slow if is \\nsmall and it can oscillate too widely if is large. \\n• To solve this problem, we can add a momentum to give each connection \\nsome inertia, forcing it to change in the direction of the downhill “force”. \\n• New Delta Rule: \\nwpq(t+1) = -    E/ wpq +    wpq(t) \\n• Where p and q are any input and hidden, or, hidden and  output units; t is a  \\ntime step or epoch; and is the momentum parameter which regulates the  \\namount of inertia of the weights. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a86f8220-3dab-4199-be3d-8424e3513c4b', embedding=None, metadata={'page_label': '42', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n36 \\n \\n \\n \\n \\n \\nUNIT - III \\n \\nIntroduction to Bayesian Learning \\n \\nImagine a situation where your friend gives you a new coin and asks you the  \\nfairness of the coin (or the probability of observing heads) without even \\nflipping the coin once. In fact, you are also aware that your friend has not  \\nmade the coin biased. In general, you have seen that coins are fair, thus you  \\nexpect the probability of observing heads is 0.50.5. In the absence of any  \\nsuch observations, yo u assert the fairness of the coin only using your past  \\nexperiences or observations with coins. \\nSuppose that you are allowed to flip the coin 1010 times in order to \\ndetermine the fairness of the coin. Your observations from the experiment  \\nwill fall under one of the following cases: \\n \\n• Case 1: observing 55 heads and 55 tails. \\n \\n• Case 2: observing hh heads and 10−h10−h tails, where h≠10−hh≠10−h. \\n \\nIf case 1 is observed, you are now more certain that the coin is a fair coin, \\nand you will decide that the probability of observing heads is 0.50.5 with  \\nmore confidence. If case 2 is observed you can either: \\n \\n1. Neglect your prior beliefs since now you have new data, decide the \\nprobability of observing heads is h/10h/10 by solely depending on recent  \\nobservations. \\n2. Adjust your belief accordingly to the value of hh that you have just observed,  \\nand decide the probability of observing heads using your recent observations. \\n \\nThe first method suggests that we use the frequentist method, where we  \\nomit our beliefs when making decisions.  However, the second method  \\nseems to be more convenient because 1010 coins are insufficient to \\ndetermine the fairness of a coin. Therefore, we can make better decisions \\nby combining our recent observations and beliefs that we have gained  \\nthrough our past experiences. It is this thinking model which uses our most  \\nrecent observations together with our beliefs or inclination for critical \\nthinking that is known as Bayesian thinking. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8815866e-1bf3-408f-9986-b33971230408', embedding=None, metadata={'page_label': '43', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Department Of CSE MRCET \\n37 \\n \\n \\n \\n \\n \\nMoreover, assume that your friend allows you to conduct another 1010 coin  \\nflips. Then we can use these new observations to further update our beliefs.  \\nAs we gain more data, we can incrementally update our beliefs  increasing \\nthe certainty of our conclusions . This is known as incremental learning,  \\nwhere you update your knowledge incrementally with new evidence. \\nBayesian learning comes into play on such occasions, where we are unable \\nto use frequentist statistics due to the drawbacks that we have discussed  \\nabove. We can use Bayesian learning to address all these drawbacks and \\neven with additional capabilities (such as incremental updates of the \\nposterior) when testing a hypothesis to estimate unknown parameters of a  \\nmachine learning models. Bayesian learning uses Bayes’ theorem to \\ndetermine the conditional probability of a hypotheses given some evidence \\nor observations. \\nThe Famous Coin Flip Experiment \\n \\nWhen we flip a coin, there are two possible outcomes - heads or tails. Of  \\ncourse, there is a third rare poss ibility where the coin balances on its edge  \\nwithout falling onto either side, which we assume is not a possible outcome  \\nof the coin flip for our discussion. We conduct a series of coin flips and  \\nrecord our observations i.e. the number of the heads (or tail s) observed for a  \\ncertain number of coin flips. In this experiment, we are trying to determine  \\nthe fairness of the coin, using the number of heads (or tails) that we observe. \\n \\nFrequentist Statistics \\n \\nLet us think about how we can determine the fairness of the coin using our  \\nobservations in the above mentioned experiment. Once we have conducted a  \\nsufficient number of coin flip trials, we can determine the frequency or the  \\nprobability of observing the heads (or tails). If we observed heads and tails  \\nwith equa l frequencies or the probability of observing heads (or tails) is  \\n0.50.5, then it can be established that the coin is a fair coin. Failing that, it is \\na biased coin. Let's denote pp as the probability of observing the heads.  \\nConsequently, as the quantity that pp deviates from 0.50.5 indicates how  \\nbiased the coin is, pp can be considered as the degree-of-fairness of the coin. \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='84d4b50b-54d0-4996-b404-02ea00246ff0', embedding=None, metadata={'page_label': '44', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n38 \\n \\n \\n \\n \\n \\nTesting whether a hypothesis is true or false by calculating the probability \\nof an event in a prolonged experiment is known as frequentist statistics. As \\nsuch, determining the fairness of a coin by using the probability of \\nobserving the heads is an example of frequentist statistics (a.k.a. frequentist \\napproach). \\nLet us now further investigate the coin flip example using the frequentist \\napproach. Since we have not intentionally altered the coin, it is reasonable to  \\nassume that we are using an unbiased coin for the experiment. When we flip  \\nthe coin 1010 times, we observe the heads 66 times. Therefore, the pp is \\n0.60.6 (note that pp is the number of heads observed over the number of total  \\ncoin flips). Hence, according to frequencies statistics, the coin is a biased \\ncoin — which opposes our assumption of a fair coin. Perhaps one of your  \\nfriends who is more skeptical than you extends this experiment to 100100  \\ntrails using the same coin. Then she observes heads 5555 times,  which \\nresults in a different pp with 0.550.55. Even though the new value for pp \\ndoes not change our previous conclusion  (i.e. that the coin is biased), this  \\nobservation raises several questions: \\n \\n• How confident are we of pp being 0.60.6? \\n \\n• How confident are of pp being 0.550.55? \\n \\n• Which of these values is the accurate estimation of pp? ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7b6cc3af-2db6-4d6b-9132-b293473ef57a', embedding=None, metadata={'page_label': '45', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='39 \\n \\n \\nDepartment of CSE MRCET \\nWill pp continue to change when we further increase the number of coin flip \\ntrails? \\n \\nWe cannot find out the exact answers to the first three questions using \\nfrequentist statistics.  We may assume that true value of pp is closer to \\n0.550.55 than 0.60.6 because the former is computed using observations from  \\na considerable number of trials compared to what we used to compute the  \\nlatter. Yet there is no way of confirming that hypothesis. However, if we  \\nfurther increase the number of trials, we may ge t a different probability from  \\nboth of the above values  for observing  the heads  and eventually, we may  \\neven discover that the coin is a fair coin. \\nNumber of coin Number of heads Probability of observing heads  \\nflips     \\n10   6 0.6 \\n50   29 0.58 \\n100   55 0.55 \\n200   94 0.47 \\n500   245 0.49 \\nTable 1 - Coin flip experiment results when increasing the number of \\ntrials \\n \\n \\nTable 1 presents some of the possible outcomes of a hypothetical coin flip  \\nexperiment when we are increasing the number of trials. The  fairness (pp) of \\nthe coin changes when increasing the number of coin -flips in this experiment. \\nOur confidence of estimated pp may also increase when increasing the \\nnumber of coin-flips, yet the frequentist statistic does not facilitate any \\nindication of t he confidence of the estimated pp value. We can attempt to  \\nunderstand the importance of such a confident measure by studying the \\nfollowing cases: \\n \\n• An experiment with an infinite number of trials guarantees pp with absolute  \\naccuracy (100% confidence). Yet, it is not practical to conduct an experiment  \\nwith an infinite number of trials and we should stop the experiment after a  \\nsufficiently large number of trials. However, deciding the value of this \\nsufficient number of trials is a challenge when using frequentist statistics. \\nIf we can determine the confidence of the estimated pp value or the inferred  \\nconclusion, in a situation where the number of trials is limited, this will allow ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='0b16fabe-45b6-4a2f-9587-8d3de272b731', embedding=None, metadata={'page_label': '46', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n40 \\n \\n \\n \\nus to  decide whether to  accept the conclusion or to  extend the experiment  \\nwith more trials until it achieves sufficient confidence. \\n \\nMoreover, we may have valuable insights or prior beliefs (for example, coins  \\nare usually fair and the coin used is not made biased intentionally, therefore  \\np≈0.5p≈0.5) that describes the value of pp. Embedding that information can  \\nsignificantly improve the accuracy of the final conclusion. Such beliefs play a  \\nsignificant role in shaping the outcome of a hypothesis test especially when  \\nwe have limited data. However, with frequentist statistics, it is not possible to \\nincorporate such beliefs or past experience to increase the accuracy of the  \\nhypothesis test. \\nSome Terms to Understand \\n \\nBefore delving into Bayesian learning, it is essential to understand the \\ndefinition of some terminologies used. I will not provide lengthy explanations  \\nof the mathematical definition since there is a lot of widely available content  \\nthat you can use to understand these concepts. \\n \\n• Random variable (Stochastic variable) - In statistics, the random variable is a  \\nvariable whose possible values  are a result of a random event. Therefore,  \\neach possible value of a random variable has some  probability attached to it  \\nto represent the likelihood of those values. \\n• Probability distribution - The function that defines the probability of different  \\noutcomes/values of a random variable. The continuous probability \\ndistributions are described using probability density functions whereas \\ndiscrete probability distributions can be represented using probability mass  \\nfunctions. \\nConditional probability - This is a measure of probability P(A|B)P(A|B) of an  \\nevent A given that another event B has occurred. \\n• Joint probability distribution \\n \\n \\nBayes’ Theorem \\n \\nBayes’ theorem describes how the conditional probability of an event or a  \\nhypothesis can be computed using evidence and prior knowledge. It is similar  \\nto concluding that our code has no bugs given the evidence that it has passed ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='59d2181e-2ca4-4409-b7c4-7bcf7380dbef', embedding=None, metadata={'page_label': '47', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n41 \\n \\n \\n \\nall the test cases, including our prior belief that we have rarely observed any  \\nbugs in our code. However, this intuition goes beyond that simple hypothesis  \\ntest where there are multiple events or hypotheses involved (let us not worry  \\nabout this for the moment). \\n \\nThe Bayes’ theorem is given by: \\n \\n \\nP(θ|X)=P(X|θ)P(θ)P(X)P(θ|X)=P(X|θ)P(θ)P(X) \\n \\n \\nI will now explain each term in Bayes’ theorem using the above example.  \\nConsider the hypothesis that there are no bugs in our code. θθ and XX denote  \\nthat our code is bug free and passes all the test cases respectively. \\n \\n• P(θ)P(θ) - Prior Probability is the probability of the hypothesis θθ being true  \\nbefore applying the Bayes’ theorem. Prior represents the beliefs that we have  \\ngained through past experience, which refers to either common sense or an  \\noutcome of Bayes’ theorem for some past observations. For the example  \\ngiven, prior probability denotes the probability of observing  no bugs in our  \\ncode. However, since  this is the  first time we are applying Bayes’ theorem,  \\nwe have to decide the priors using other means \\n(Otherwise we could use the previous posterior as the new prior). Let us  \\nassume that it  is very unlikely to find bugs  in our code because rarely have  \\nwe observed bugs in our code in the past. With our past experience of \\nobserving fewer bugs in our code, we can assign our prior P(θ)P(θ) with a  \\nhigher probability. However, for now, let us assume that P(θ)=pP(θ) \\nThis term depends on the test coverage of the test cases. Even though we do  \\nnot know the value of this term without proper measurements, in order to  \\ncontinue this discussion let us assume that P(X|¬θ)=0.5P(X|¬θ)=0.5. \\nAccordingly, \\nP(X)=1×p+0.5×(1−p)=0.5(1+p)P(X)=1×p+0.5×(1−p)=0.5(1+p) \\n \\n• P(θ|X)P(θ|X) - Posteriori probability denotes the  conditional probability of  \\nthe hypothesis θθ after observing the evidence XX. This is the probability of  \\nobserving no bugs in our code given that it passes all the test cases. Since we ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fc2d4e46-1c1f-416c-9713-df4dccd191e1', embedding=None, metadata={'page_label': '48', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n42 \\n \\n \\n \\nnow know the values for the other three terms in the Bayes’ theorem, we can  \\ncalculate the posterior probability using the following formula: \\n \\nP(θ|X)=1×p0.5(1+p)P(θ|X)=1×p0.5(1+p) \\nWe can also calculate the probability of observing a bug, given that our code \\npasses all the test cases P(¬θ|X)P(¬θ|X) . \\nP(¬θ|X)=P(X|¬θ).P(¬θ)P(X)=0.5×(1−p)0.5×(1+p)=(1−p)(1+p)P(¬θ|X)=P(X|¬  \\nθ).P(¬θ) \\nP(X)=0.5×(1−p)0.5×(1+p)=(1−p)(1+p) \\nWe now know both conditional probabilities of observing a bug in the code  \\nand not observing the bug in the code. Yet how are we going to confirm the  \\nvalid hypothesis using these posterior probabilities? \\n \\nMaximum a Posteriori (MAP) \\n \\nWe can use MAP to determine the valid hypothesis from a set of hypotheses.  \\nAccording to MAP, the hypothesis that has the maximum posterior \\nprobability is considered as the valid hypothesis. Therefore, we can express  \\nthe hypothesis θMAPθMAP that is concluded using MAP as follows: \\nθMAP=argmaxθP(θi|X)=argmaxθ(P(X|θi)P(θi)P(X))θMAP=argmaxθP(θi|X)  \\n=argmaxθ(P(X|θ i)P(θi)P(X)) \\nThe argmaxθargmaxθ operator estimates the event or hypothesis θiθi that \\nmaximizes the posterior probability P(θi|X)P(θi|X). Let us apply MAP to the \\nabove example in order to determine the true hypothesis: \\nθMAP=argmaxθ{θ:P(θ|X)=p0.5(1+p),¬θ:P(¬θ|X)=(1−p)(1+p)}θMAP=argma  \\nxθ{θ:P(θ|X)=p0.5(1+p),¬θ:P(¬θ|X)=(1−p)(1+p)} ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='65693c29-85ed-4324-aaa0-cfe2b8c03255', embedding=None, metadata={'page_label': '49', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n43 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFigure 1 - P(θ|X)P(θ|X) and P(¬θ|X)P(¬θ|X) when changing the \\nP(θ)=pP(θ)=p Figure 1 illustrates how the posterior probabilities of possible  \\nhypotheses change with the value of prior probability. Unlike  frequentist \\nstatistics where our belief or past experience had no influence on the \\nconcluded hypothesis, Bayesian learning is capable of incorporating our \\nbelief to improve the accuracy of predictions. Assuming that we have fairly  \\ngood programmers and therefore the probability of observing a bug is \\nP(θ)=0.4P(θ)=0.4 , then we find the θMAPθMAP: \\nMAP=argmaxθ{θ:P(|X)=0.40.5(1+0.4),¬θ:P(¬θ|X)=0.5(1−0.4)0.5(1+0.4)}=ar  \\ngmaxθ{θ:P(θ|X)=0.57,¬θ:P(¬θ|X)=0.43}=θ⟹No bugs present in our \\ncodeMAP=argmaxθ{θ:P(|X)=0.40.5(1+0.4),¬θ:P(¬θ|X)=0.5(1−0.4)0.5(1+0.4  \\n)}=argmaxθ{θ:P(θ|X)=0.57,¬θ:P(¬θ|X)=0.43}=θ⟹No bugs present in our \\ncode \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8a7d1e87-f736-43ec-9deb-2e2490717e64', embedding=None, metadata={'page_label': '50', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n44 \\n \\n \\n \\nHowever, P(X)P(X) is independent of θθ, and thus P(X)P(X) is same for all  \\nthe events or hypotheses. Therefore, we can simplify the θMAPθMAP \\nestimation, without the denominator of each posterior computation as shown  \\nbelow: θMAP=argmaxθ(P(X|θi)P(θi))θMAP=argmaxθ(P(X|θi)P(θi))  \\nNotice that MAP estimation algorithms do not compute posterior probability  \\nof each hypothesis to decide which is the most probable hypothesis. \\nAssuming that our hypothesis space is continuous (i.e. fairn ess of the coin  \\nencoded as probability of observing heads, coefficient of a regression model,  \\netc.), where endless possible hypotheses are present even in  the smallest \\nrange that the human mind can think of, or for even a discrete hypothesis  \\nspace with a large number of possible outcomes for an event, we do not need  \\nto find the posterior of each hypothesis in order to decide which is the most  \\nprobable hypothesis. Therefore, the practical implementation of MAP \\nestimation algorithms use approximation techniques, which are capable of  \\nfinding the most probable hypothesis without computing posteriors or only \\nby computing some of them. \\n \\nUsing the Bayesian theorem, we can now incorporate our belief as the prior  \\nprobability, which was not possible when we used frequentist statistics. \\nHowever, we still have the problem of deciding a sufficiently large number of  \\ntrials or attaching a confidence to the concluded hypothesis. This is because  \\nthe above example was solely designed to introduce the Bayesian theorem \\nand each of its terms. Let us now gain a better understanding of \\nBayesian learning to learn about the full potential of Bayes’ theorem. \\n \\nBinomial Likelihood \\nThe likelihood for the coin flip experiment is given by the probability of  \\nobserving heads out of a ll the coin flips given the fairness of the coin. As we  \\nhave defined the fairness of the coins (θθ) using the probability of observing  \\nheads for each coin flip, we can define the probability of observing heads or ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ff79215d-d72a-4c0b-b6c9-f8d9987d5964', embedding=None, metadata={'page_label': '51', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n45 \\n \\n \\n \\ntails given the fairness of the coin P(y|θ)P(y|θ) where y=1y=1 for observing \\nheads and y=0y=0 for observing tails. Accordingly: \\nP(y=1|θ)=θP(y=0|θ)=(1−θ)P(y=1|θ)=θP(y=0|θ)=(1−θ)  \\nNow that we have defined two conditional probabilities for each outcome \\n \\nabove, let us now try to find the P(Y=y|θ)P(Y=y|θ) joint probability of \\nobserving heads or tails: \\nP(Y=y|θ)={θ, if y=11−θ, otherwise P(Y=y|θ)={θ, if y=11−θ, otherwise \\nNote that yy can only take either 00 or 11, and θθ will lie within the range of  \\n[0,1][0,1]. We can rewrite the a bove expression in a single expression as  \\nfollows: \\nP(Y=y|θ)=θy×(1−θ)1−yP(Y=y|θ)=θy×(1−θ)1−y \\nThe above equation represents the likelihood of a single test coin flip \\nexperiment. \\nInterestingly, the likelihood function of the single coin flip experiment is  \\nsimilar to the Bernoulli probability distribution. The Bernoulli distribution is  \\nthe probability distribution of a single trial experiment with only two \\nopposite   outcomes.   As   the   Bernoulli   probability   distribution   is   the \\nsimplification of Binomial probability distribution for a single trail, we can \\n \\nrepresent the likelihood of a coin flip experiment that we ob serve kk number \\nof heads out of NN number of trials as a Binomial probability distribution as  \\nshown below: \\nP(k,N|θ)=(Nk)θk(1−θ)N−k ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='0bf54a36-cbf2-4c30-867a-2ffb9a37763e', embedding=None, metadata={'page_label': '52', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n46 \\n \\n \\n \\nMaximum likelihood estimation method (MLE) \\n \\nThe likelihood function indicates how likely the observed sample is as a  \\nfunction of possible parameter values. Therefore, maximizing the likelihood  \\nfunction determines the parameters that are most likely to produce the \\nobserved data. From a statistical point of view, MLE is usually recommended  \\nfor large samples because it is versatile, applicable to most models and \\ndifferent types of data, and produces the most precise estimates. \\n \\nLeast squares estimation method (LSE) \\n \\nLeast squares estimates are calculated by fitting a regression line to the points  \\nfrom a data set that has the minimal sum of the deviations squared (least  \\nsquare error). In reliability analysis, the line and the data are plotted on a  \\nprobability plot. \\nBayes Optimal Classifier \\n \\nThe Bayes optimal classifier is a probabilistic model that make s the most  \\nprobable prediction for a new example, given the training dataset. \\n \\nThis model is also referred to as the Bayes optimal learner, the Bayes \\nclassifier, Bayes optimal decision boundary, or the Bayes optimal \\ndiscriminant function. \\n \\nGibbs Sampling Algorithm \\nWe start off by selecting an initial value for the random variables X & Y. \\nThen, we sample from the conditional probability distribution of X given Y =  \\nY⁰ denoted p(X|Y⁰). In the next step, we sample a new value of Y conditional  \\non X¹, which we just computed. We repeat the procedure for an additional n - \\n1 iterations, alternating between drawing a new sample from the conditional  \\nprobability distribution of X and the conditional probability distribution of Y, \\ngiven the current value of the other random variable. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='baec49e7-18e2-4a80-851c-396e3b97dc16', embedding=None, metadata={'page_label': '53', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n47 \\n \\n \\n \\nLet’s take a look at an example. Suppose we had the following posterior and \\nconditional probability distributions. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNaive Bayes Classifier Algorithm \\n• Naïve Bayes algorithm is a supervised learning algorithm, which is based on \\nBayes theorem and used for solving classification problems. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='90457503-0ddb-4f26-9f67-ad277e4c7133', embedding=None, metadata={'page_label': '54', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n48 \\n \\n \\n \\n• It is mainly used in text classification that includes a high-dimensional \\ntraining dataset. \\n• Naïve Bayes Classifier is one of the simple and most effective Classification  \\nalgorithms which helps in building the fast machine learning models that can  \\nmake quick predictions. \\n• It is a probabilistic classifier, which means it predicts on the basis of the  \\nprobability of an object. \\n• Some popular examples of Naïve Bayes Algorithm are spam filtration, \\nSentimental analysis, and classifying articles. \\nEXAMPLE \\nSuppose we have a dataset of weather conditions and corresponding target  \\nvariable \" Play\". So using this dataset we need to decide that whether we  \\nshould play or not on a particular day according to the weather conditions. So  \\nto solve this problem, we need to follow the below steps: \\n \\n1. Convert the given dataset into frequency tables. \\n2. Generate Likelihood table by finding the probabilities of given features. \\n3. Now, use Bayes theorem to calculate the posterior probability.  \\nProblem: If the weather is sunny, then the Player should play or not? \\nSolution: To solve this, first consider the below dataset: \\n \\nOutlook \\n  \\nPlay \\n0 Rainy Yes \\n1 Sunny Yes \\n \\n2 \\n \\nOvercast \\n \\nYes \\n3 Overcast Yes \\n \\n4 \\n \\nSunny \\n \\nNo \\n5 Rainy Yes \\n \\n6 \\n \\nSunny \\n \\nYes \\n ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f7b40f8b-aed5-4453-8e75-e7e5fcab50af', embedding=None, metadata={'page_label': '55', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\" \\nDepartment Of CSE MRCET \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFrequency table for the Weather Conditions: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLikelihood table weather condition: \\nWeather No Yes   \\n \\nOvercast \\n \\n0 \\n \\n5 \\n \\n5/14= 0.35 \\nRainy 2 2 4/14=0.29 \\n \\nSunny \\n \\n2 \\n \\n3 \\n \\n5/14=0.35 \\nAll 4/14=0.29 10/14=0.71  \\n \\nApplying Bayes'theorem: \\n \\nP(Yes|Sunny)= P(Sunny|Yes)*P(Yes)/P(Sunny) \\n49 \\n \\n7 Overcast Yes \\n \\n8 \\n \\nRainy \\n \\nNo \\n9 Sunny No \\n \\n10 \\n \\nSunny \\n \\nYes \\n11 Rainy No \\n \\n12 \\n \\nOvercast \\n \\nYes \\n13 Overcast Yes \\n \\n \\nWeather \\n \\nYes \\n \\nNo \\n \\nOvercast \\n \\n5 \\n \\n0 \\n \\nRainy \\n \\n2 \\n \\n2 \\n \\nSunny \\n \\n3 \\n \\n2 \\nTotal 10 5 \\n \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='58b0cac7-3727-4757-bb04-6afe22f82411', embedding=None, metadata={'page_label': '56', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n50 \\n \\n \\n \\nP(Sunny|Yes)= 3/10= 0.3 \\n \\nP(Sunny)= 0.35 \\nP(Yes)=0.71 \\nSo P(Yes|Sunny) = 0.3*0.71/0.35= 0.60 \\nP(No|Sunny)= P(Sunny|No)*P(No)/P(Sunny) \\nP(Sunny|NO)= 2/4=0.5 \\nP(No)= 0.29 \\n \\nP(Sunny)= 0.35 \\n \\nSo P(No|Sunny)= 0.5*0.29/0.35 = 0.41 \\n \\nBayesian Belief Network: \\n \\nIt is a graphical representation of different probabilistic relationships among \\nrandom variables in a  particular set. It is a classifier with no dependency on \\nattributes i.e it is condition independent. Due to its feature of joint probability, the  \\nprobability in Bayesian Belief Network is derived, based on a condition — \\nP(attribute/parent) i.e probability of an attribute, true over parent attribute. \\n \\nConsider this example: \\n \\n \\n \\n \\n• In the above figure, we have an alarm ‘A’ – a node, say installed in a house \\nof a person ‘gfg’, which rings upon two probabilities i.e burglary ‘B’ and fire \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c0b6c019-8fae-456c-9911-cde7953e0564', embedding=None, metadata={'page_label': '57', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n51 \\n \\n \\n \\n‘F’, which are – parent nodes of the alarm node. The alarm is the parent node  \\nof two probabilities P1 calls ‘P1’ & P2 calls ‘P2’ person nodes. \\n \\n• Upon the instance of  burglary and fire, ‘P1’ and ‘P2’ call person ‘gfg’,  \\nrespectively. But, there are few drawbacks in this case, as sometimes ‘P1’  \\nmay forget to call the person ‘gfg’, even after hearing the alarm, as he has a  \\ntendency to forget things, quick.  Similarly, ‘P2’, sometimes fails to call the  \\nperson ‘gfg’, as he is only able to hear the alarm, from a certain distance. \\nExpectation-Maximization Algorithm \\nIn the real -world applications of machine learning, it is very common that  \\nthere are many relevant features available for learning but only a small subset  \\nof them are observable. So, for the variables which are sometimes observable  \\nand sometimes not, then  we can use the instances when that variable is \\nvisible is observed for the purpose of learning and then predict its value in the  \\ninstances when it is not observable. \\nOn the other hand, Expectation-Maximization algorithm can be used for the  \\nlatent variables (variables that are not directly observable and are actually  \\ninferred from the values of the other observed variables) too in order to  \\npredict their values with the condition that the general form of probability  \\ndistribution governing those latent variables is known to us. This algorithm is  \\nactually at the base of many unsupervised clustering algorithms in the field of  \\nmachine learning. \\nIt was explained, proposed and given its name in a paper published in 1977 \\nby Arthur Dempster, Nan Laird, and Donald Rubin. It is used to find the local \\nmaximum likelihood parameters of a statistical model in the cases where  \\nlatent variables are involved and the data is missing or incomplete. \\n \\n \\nAlgorithm: \\n1. Given a set of incomplete data, consider a set of starting parameters. \\n2. Expectation step (E – step): Using the observed available data of the \\ndataset, estimate (guess) the values of the missing data. \\n3. Maximization step (M – step): Complete data generated after the \\nexpectation (E) step is used in order to update the parameters. \\n4. Repeat step 2 and step 3 until convergence. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ee9182eb-076e-47e1-a2d8-9189f5a7efa7', embedding=None, metadata={'page_label': '58', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n52 \\n \\n \\n \\n \\nThe essence of Expectation -Maximization algorithm is to use the available  \\nobserved data of the dataset to estimate the missing data and then using that  \\ndata to update the values of the parameters. Let us understand the EM \\nalgorithm in detail. \\n• Initially, a set of initial values of the parameters are considered. A set of  \\nincomplete observed data is given to the system with the assumption that the  \\nobserved data comes from a specific model. \\n• The next step is known as “Expectation” – step or E-step. In this step, we use  \\nthe observed data in order to estimate or guess the values of the missing or  \\nincomplete data. It is basically used to update the variables. \\n• The next step is known as “Maximization”-step or M-step. In this step, we \\nuse the complete data generated  in the preceding “Expectation”  – step in  \\norder to update the values of the parameters. It is basically used to update the  \\nhypothesis. \\n• Now, in the fourth step, it is checked whether the values are converging or  \\nnot, if yes, then stop otherwise repeat step-2 and step-3 i.e. “Expectation” – \\nstep and \\n“Maximization” – step until the convergence occurs. \\n \\nFlow chart for EM algorithm \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4de6c00c-6f0c-4b2d-8687-f62e1fe794d9', embedding=None, metadata={'page_label': '59', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n53 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUsage of EM algorithm \\n• It can be used to fill the missing data in a sample. \\n• It can be used as the basis of unsupervised learning of clusters. \\n• It can be used for the purpose of estimating the parameters of Hidden Markov \\nModel (HMM). \\n• It can be used for discovering the values of latent variables. \\n \\nAdvantages of EM algorithm \\n• It is always guaranteed that likelihood will increase with each iteration. \\n• The E-step and M-step are often pretty easy for many problems in terms of \\nimplementation. \\n• Solutions to the M-steps often exist in the closed form. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f7d41a28-952c-4f6d-a934-097160d61b6e', embedding=None, metadata={'page_label': '60', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n54 \\n \\n \\n \\nInstance-based learning \\nThe Machine Learning systems which are categorized as instance-based \\nlearning are the systems that learn the training examples by heart and then  \\ngeneralizes to new instances based on some similarity measure. It is called  \\ninstance-based because it builds the hypotheses from the training instances.  \\nIt is also known as memory-based learning or lazy-learning. The time  \\ncomplexity of this algorithm depends upon the size of training data. The  \\nworst-case time complexity of this algorithm is O (n), where n is the \\nnumber of training instances. \\nFor example, If we were to create a spam filter with an instance-based \\nlearning algorithm, instead of just flagging emails that are already marked as  \\nspam emails, our spam filter would be programmed to also flag  emails that \\nare very  similar to  them. This  requires a measure of resemblance between  \\ntwo emails. A similarity measure between two emails could be the same  \\nsender or the repetitive use of the same keywords or something else. \\n \\n \\nAdvantages: \\n1. Instead of estimating for the entire instance set, local approximations can be \\nmade to the target function. \\n2. This algorithm can adapt to new data easily, one which is collected as we go. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nDisadvantages: \\n1. Classification costs are high \\n2. Large amount of memory required to store the data, and each  \\nquery involves starting the identification of a local model from scratch.  \\nSome of the instance-based learning algorithms are : \\n1. K Nearest Neighbor (KNN) \\n2. Self-Organizing Map (SOM) \\n3. Learning Vector Quantization (LVQ) \\n4. Locally Weighted Learning (LWL) ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2cce1757-e0da-4279-8c8d-6b5b36c660c3', embedding=None, metadata={'page_label': '61', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n55 \\n \\n \\n \\n \\n \\nK-Nearest Neighbor(KNN) Algorithm \\n• K-Nearest Neighbour is one of the simplest Machine Learning algorithms  \\nbased on Supervised Learning technique. \\n• K-NN algorithm assumes the similarity between the new case/data and \\navailable cases and put the new case into the category that is most similar to  \\nthe available categories. \\n• K-NN algorithm stores all the available data and classifies a new data point  \\nbased on the similarity. This means when new data appears then it can be  \\neasily classified into a well suite category by using K- NN algorithm. \\n• K-NN algorithm can be used for Regression as well as for Classification but  \\nmostly it is used for the Classification problems. \\n• K-NN is a non-parametric algorithm , which means it does not make any  \\nassumption on underlying data. \\n• It is also called a lazy learner algorithm because it does not learn from the  \\ntraining set immediately instead it stores the dataset and at the time of \\nclassification, it performs an action on the dataset. \\n• KNN algorithm at the training phase just stores the dataset and when it gets  \\nnew data, then it classifies that data into a category that  is much similar to the \\nnew data. \\nWorking of KNN Algorithm \\nK-nearest neighbours (KNN) algorithm uses  ‘feature similarity’ to  predict \\nthe values of new data  points which further means that the new data point  \\nwill be assigned a value based on how closely it matches the points in the  \\ntraining set. We can understand its working with the help of following steps \\n− \\nStep 1 − For implementing any algorithm, we need dataset. So during the \\nfirst step of KNN, we must load the training as well as test data. \\nStep 2 − Next, we need to choose the value of K i.e. the nearest data points. \\nK can be any integer. \\nStep 3 − For each point in the test data do the following ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='dc3cf000-5124-4e1e-ac7a-58aa6c5e3f60', embedding=None, metadata={'page_label': '62', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n56 \\n \\n \\n \\n• 3.1 − Calculate the distance between test data  and each row of training data  \\nwith the help of any of the method namely: Euclidean, Manhattan or \\nHamming distance. The most commonly used method to calculate distance is  \\nEuclidean. \\n• 3.2 − Now, based on the distance value, sort them in ascending order. \\n• 3.3 − Next, it will choose the top K rows from the sorted array. \\n• 3.4 − Now, it will assign a class to the test point based on most frequent class  \\nof these rows. \\nStep 4 – End \\nEXAMPLE : \\n \\nCase Based Reasoning \\n \\nAs we know Nearest Neighbour classifiers stores training tuples as points in \\nEuclidean space. But Case-Based Reasoning classifiers (CBR) use a \\ndatabase of problem solutions to solve new problems. It stores the tuples or  \\ncases for problem-solving as complex symbolic descriptions. \\nHow CBR works? \\nWhen a new case arrises to classify, a Case -based Reasoner(CBR) will first  \\ncheck if an identical training case exists. If one is found, then the \\naccompanying solution to that case is returned. If no identical case is found,  \\nthen the CBR will search for training c ases having components that are \\nsimilar to those of the new case. Conceptually, these training cases may be  \\nconsidered as neighbours of the new case. If cases are represented as graphs,  \\nthis involves searching for subgraphs that are similar to subgraphs wi thin the \\nnew case. The CBR tries to combine the solutions of the neighbouring \\ntraining cases to propose a solution for the new case. If compatibilities arise  \\nwith the individual solutions, then backtracking to search for other solutions \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='63a27588-5d14-4fc6-ac18-24e6da22e53d', embedding=None, metadata={'page_label': '63', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n57 \\n \\n \\n \\nmay be necessary. The CBR may employ background knowledge and \\nproblem-solving strategies to propose a feasible solution. \\nApplications of CBR includes: \\n1. Problem resolution for customer service help desks, where cases describe \\nproduct-related diagnostic problems. \\n2. It is also applied to areas such as engineering and law, where cases are either \\ntechnical designs or legal rulings, respectively. \\n3. Medical educations, where patient case histories and treatments are used to \\nhelp diagnose and treat new patients. \\n \\nChallenges with CBR \\n• Finding a good similarity metric (eg for matching subgraphs) and suitable \\nmethods for combining solutions. \\n• Selecting salient features for indexing training cases and the development of \\nefficient indexing techniques. \\n \\nCBR becomes more intelligent as the number of the trade-off between \\naccuracy and efficiency evolves as the number of stored cases becomes very  \\nlarge. But after a certain point, the system’s efficiency will suffer as the time  \\nrequired to search for and process relevant cases increases. \\n \\n \\nSome differences on eager and lazy learning \\n• Eager learning methods construct general, explicit description of the target \\nfunction based on the provided training examples. \\n• Lazy learning methods simply store the data and generalizing beyond these \\ndata is postponed until an explicit request is made. \\n• Lazy learning methods can construct a different approximation to the target \\nfunction for each encountered query instance. \\n \\nLazy learning is very suitable for complex and incomplete problem domains, \\nwhere a complex target function can be represented by a collection of less  \\ncomplex local approximations. \\nEager learning methods use the same approximation to the target function,  \\nwhich must be learned based on training examples and before input queries  \\nare observed. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='60ea04fd-3057-49c1-b1cf-7ba1cbcd3b24', embedding=None, metadata={'page_label': '64', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n58 \\n \\n \\n \\nUNIT - IV \\nPATTERN COMPARISON TECHNIQUES \\n \\n \\nPattern recognition is a process of finding regularities and similarities in data  \\nusing machine learning data. Now, these similarities can be found based on  \\nstatistical analysis, historical data, or the already gained knowledge by the \\nmachine itself. A pattern is a regularity in the world or in abstract notions. If we  \\ndiscuss sports, a description of a type would be a pattern. If a person keeps  \\nwatching videos related to cricket, Y ouTube wouldn’t recommend them chess  \\ntutorials videos. \\nExamples: Speech recognition, speaker identification, multimedia document  \\nrecognition (MDR), automatic medical diagnosis. \\n \\nBefore searching for a pattern there are some certain steps and the first one is to \\ncollect the data from the real world. The collected data needs to be filtered and  \\npreprocessed so that its system can  extract the features  from the data. Then  \\nbased on the type of the data system will choose the appropriate algorithm  \\namong Classification, Regression, and Regression to recognize the pattern. \\n• Classification. In classification, the algorithm assigns labels to data based on \\nthe predefined features. This is an example of supervised learning. \\n• Clustering. An algorithm splits data into a number of clusters based on the  \\nsimilarity of features. This is an example of unsupervised learning. \\n• Regression. Regression algorithms try to find a relationship between variables  \\nand predict unknown dependent variables based on known data. It is based on  \\nsupervised learning. [2] \\n• Features can be represented as continuous, discrete, or discrete binary \\nvariables. A feature is basically a function of one or more measurements, \\ncomputed to quantify the significant characteristics of the object. The feature is  \\none of the most important components in the Pattern Recognition system. \\nExample: consider a football, shape, size and color, etc. are features of the  \\nfootball. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8f1d7a38-700f-41c9-a716-7831eb41507f', embedding=None, metadata={'page_label': '65', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n59 \\n \\n \\nA feature vector is a set of features that are taken together. \\nExample: In the above example of football, if all the features (shape, size, color  \\netc.) taken together then the sequence is feature vector ([shape, size, color]). \\nThe feature vector is the sequence of features represented as an n -dimensional \\ncolumn vector. In the case of speech, MFCC (Mel-frequency Cepstral \\nCoefficient) is the spectral features of the speech. The sequence of the first 13  \\nfeatures forms a feature vector. \\n \\n \\nTemporal patterns \\n \\n \\nTemporal patterns are  one of the pattern comparison techniques that is defined  \\nas a segment of signals that recurs frequently in the whole temporal signal  \\nsequence. For example, the temporal signal sequences could be the movements  \\nof head, hand, and body, a piece of music, and so on. \\nTemporal abstraction and data mining are two research fields that have tried to  \\nsynthesis time  oriented data  and bring out  an understanding on the hidden  \\nrelationships t hat may exist between time oriented events. In clinical settings,  \\nhaving the  ability to know the hidden  relationships on patient data  as they \\nunfold could help save a life by aiding in detection of conditions that are not  \\nobvious to clinicians and healthcare workers. Understanding the hidden patterns  \\nis a huge challenge due to the exponential search space unique to time -series \\ndata. In this paper, we propose a temporal pattern recognition model based on  \\ndimension reduction and similarity measures th ereby maintaining the temporal  \\nnature of the raw data \\n \\n \\nINTRODUCTION \\nTemporal pattern processing is important  for various  intelligent behaviours, \\nincluding hearing, vision, speech, music and motor control. Because we live in  \\nan ever-changing environment, an intelligent system, whether it be a human or a  \\nrobot, must encode patterns over time, recognize and generate temporal \\npatterns. Time is embodied in a temporal pattern in two different ways: • \\nTemporal order. It refers to the ordering among the components  of a sequence.  \\nFor example, the sequence N-E-T is different from T-E-N. Temporal order may ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ba81823e-442d-4811-9439-8aba19ef982c', embedding=None, metadata={'page_label': '66', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n60 \\n \\n \\nalso refer to a syntactic structure, such as subject-verb-object, where each \\ncomponent may be any of a category of possible symbols \\n• Time duration. Duration can play a critical role for temporal processing. In  \\nspeech recognition, for example, we want rate invariance while distinguishing  \\nrelative durations of the vowel /i:/ (as in beet) and /i/ (as in bit) \\nTEMPORAL PATTERN RECOGNITION \\nThe shared goal of all STM models is to make input history available \\nsimultaneously when recognition takes place. With a  STM model in place,  \\nrecognition is not much different from the recognition of static patterns. \\n \\nTemplate Matching Using Hebbian Learning \\nThe architecture for this type of recognition is simply a two -layer network: the  \\ninput layer that incorporates STM, and the sequence recognition layer where  \\neach unit encodes an individual sequence. The recognition scheme is essentially \\ntemplate matching, where templates are formed  through following Hebbian \\nlearning \\n \\nWij(t) = Wij(t–1) + C si (t)[xj (t) – Wij(t–1)] \\n \\nwhere Wij is the connection weight from unit xj in the input layer to sequence  \\nrecognizer si in the recognition layer. Parameter C controls learning rate. \\nHebbian learning is applied after the presentation of the entire sequence is  \\ncompleted. The templates thus formed can be used to recognize specific input  \\nsequences. The recognition layer typically includes recurren t connections for  \\nselecting a winner by self -organization (e.g. winner -take-all) during training or  \\nrecognition. \\n \\nAssociative Memory Approach \\nThe dynamics of the Hopfield associative memory model can be characterized \\nas evolving towards the memory state most similar to the current input pattern. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='758ae0da-c44c-405d-b2b5-a2c010513a86', embedding=None, metadata={'page_label': '67', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n61 \\n \\n \\nIf one views each memory state as a category, the Hopfield net performs pattern  \\nrecognition: the recalled category is the recognized pattern. This process of  \\ndynamic evolution can also be viewed as an optimization process, which \\nminimizes a cost function until equilibrium is reached. \\nWith normalized exponential kernel STM, Tank and Hopfield (1987) described \\na recognition network based on associative memory dynamics. A layer of \\nsequence recognizers receives inputs from the STM model. Each recognizer  \\nencodes a different template sequence by its unique weight vector acting upon  \\nthe inputs in STM. In addition, recognizers form a competitive network. The  \\nrecognition process uses the current input sequence (evidence) to bias a \\nminimization process so that the most similar template wins the competition,  \\nthus activating its corresponding recognizer. Due to  the exponential  kernels, \\nthey demonstrated that recognition is fairly robust to time warping, distortions \\nin duration. A similar architecture is later applied to speakerindependent spoken  \\ndigit recognition. \\n \\nMultilayer Perceptrons \\nA popular approach to temporal pattern learning is multilayer perceptrons \\n(MLP). MLPs have been demonstrated to be effective for static pattern \\nrecognition. It is natural to combine MLP with an STM model to do temporal  \\npattern recognition. For example, using delay line STM Waibel et al. (1989)  \\nreported an architecture called Time Delay Neural Networks (TDNN) for \\nspoken phoneme recognition. Besides the input layer, TDNN uses 2 hidden  \\nlayers and an output layer where each unit encodes one phoneme. The feed  \\nforward connections converge from the input layer to each successive layer so  \\nthat each unit  in a specific layer receives inputs within a limited time window  \\nfrom the previous layer. They demonstrated good recognition performance: for  \\nthe three stop consonants /b/, /d/, and /g/, the accuracy of speaker dependent  \\nrecognition reached 98.5%. \\nDYNAMIC TIME WARPING \\nSounds like time traveling or some kind of future technic, however, it is not.  \\nDynamic Time Warping is used to compare the similarity or calculate the ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='585d4e5a-127a-41ed-ac59-669e2dcac938', embedding=None, metadata={'page_label': '68', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n62 \\n \\n \\ndistance between two arrays or time series with different length. Suppose we \\nwant to calculate the distance of two equal-length arrays: \\na = [1, 2, \\n3] b = [3, \\n2, 2] \\nHow to do that? One obvious way is to match up a and b in 1 -to-1 fashion and  \\nsum up the total distance of each component. This sounds easy, but what if a \\nand b have different lengths? \\na = [1, 2, 3] b \\n= [2, 2, 2, 3, \\n4] \\nHow to match them up? Which should map to which? To solve the problem,  \\nthere comes dynamic time warping. Just as its name indicates, to warp the series  \\nso that they can match up. \\n \\nUse Cases \\nBefore digging into the algorithm, you might have the question that is it useful?  \\nDo we really need to compare the distance between two unequal -length time  \\nseries? \\nYes, in a lot of scenarios DTW is playing a key role. \\nSound Pattern Recognition \\nOne use case is to detect the sound pattern of the same kind. Suppose we want \\nto recognise the voice of a person by analysing his sound track, and we are able  \\nto collect his sound track of saying Hello in one scenario. However, people  \\nspeak in the same word in different ways, what if he speaks hello in a much  \\nslower pace like Heeeeeeelloooooo , we will need an algorithm to match up the  \\nsound track of different lengths and be able to identify they come from the same  \\nperson. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ce13a58e-401f-458b-ac74-19ba21a742fe', embedding=None, metadata={'page_label': '69', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n63 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStock Market \\nIn a stock market, people always hope to be able to predict the future, however  \\nusing general machine learning algorithms can be exhaustive, as most prediction  \\ntask requires test and training set to have the same dimension of features. \\nHowever, if you ever speculate in the stock market, you will know that even the  \\nsame pattern of a stock can have very different length reflection on klines and  \\nindicators. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='29ad55c7-1f0c-4b0e-b915-b79f19e83500', embedding=None, metadata={'page_label': '70', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n64 \\n \\n \\n \\n \\n \\n \\n \\nIn time series analysis, dynamic time warping (DTW) is one of the algorithms \\nfor measuring similarity between two temporal sequences, which may vary in  \\nspeed. DTW has been applied to temporal sequences of video, audio, and \\ngraphics data — indeed, any data that can be turned into a linear sequence can \\nbe analysed with DTW. \\nThe idea to compare arrays with different length is to build one -to-many and  \\nmany-to-one matches so that the total distance can be minimised between the  \\ntwo. \\n \\n \\n \\n \\nSuppose we have two different arrays red and blue with different length: \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8df8adcc-526f-4a76-b1df-8083d47a5fa5', embedding=None, metadata={'page_label': '71', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n65 \\n \\n \\n \\n \\n \\n \\n \\nClearly these two series follow the same pattern, but the blue curve is longer \\nthan the red. If we apply the one -to-one match, shown in the top, the mapping is  \\nnot perfectly synced up and the tail of the blue curve is being left out. \\n \\nDTW overcomes the issue by developing a one -to-many match so that the  \\ntroughs and peaks with the same pattern are perfectly matched, and there is no  \\nleft out for both curves(shown in the bottom top). \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9035192a-eafa-4295-8c82-0f5c57a625d4', embedding=None, metadata={'page_label': '72', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department Of CSE MRCET \\n66 \\n \\n \\nl > \\nk \\nRules \\nIn general, DTW is a method that calculates an optimal match between  two \\ngiven sequences (e.g. time series) w ith certain restriction and rules(comes from  \\nwiki): \\n \\n• Every index from the first sequence must be matched with one or more indices \\nfrom the other sequence and vice versa \\n \\n• The first index from the first sequence must be matched with the first index from  \\nthe other sequence (but it does not have to be its only match) \\n• The last index from the first sequence must be matched with the last index from \\nthe other sequence (but it does not have to be its only match) \\n• The mapping of the indices from the first sequence to indices from the other \\nsequence must be monotonically increasing, and vice versa, i.e. if \\nfrom the first sequence, then \\nare indices \\nthere must not be two indices in the other sequence, such \\n \\n \\nthat index i is matched with index  l and index j is matched with index  k , and \\nvice versa. \\nThe optimal match is denoted by the match that satisfies all the restrictions and  \\nthe rules and that has the minimal cost, where the cost is computed as the sum of  \\nabsolute differences, for each matched pair of indices, between their values. \\nj > i ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ea3be9af-fcff-4e9e-bd60-c87e5255a430', embedding=None, metadata={'page_label': '73', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n67 \\n \\n \\nIntroduction to Clustering: \\nIt is basically a type of unsupervised learning method. An unsupervised learning method \\nis a method in which we draw references from datasets consisting of input data without  \\nlabelled responses. Generally, it is used as a process to find meaningful structure, \\nexplanatory underlying processes, generative features, and groupings inherent in a set of  \\nexamples. \\nClustering is the task of dividing the population or data points into a number of groups  \\nsuch that data points in the same groups are more similar to other data points in the same  \\ngroup and dissimilar to the data points in other groups. It is basically a collection of  \\nobjects on the basis of similarity and dissimilarity between them. \\nFor ex– The data points in the graph below clustered together can be classified into one  \\nsingle group. We can distinguish the clusters, and we can identify that there are 3 clusters  \\nin the below picture. \\n \\n \\nIt is not necessary for clusters to be spherical. Such as: \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fe011409-62f4-4075-90e1-a6f359097cc0', embedding=None, metadata={'page_label': '74', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n68 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nDBSCAN: Density-based Spatial Clustering of Applications with Noise \\nThese data points are clustered by using the basic concept that the data point lies within  \\nthe given constraint from the cluster center. Various distance methods and techniques are  \\nused for the calculation of the outliers. \\nWhy Clustering? \\nClustering is very much important as it determines the intrinsic grouping among the  \\nunlabelled data present. There are no criteria for goo d clustering. It depends on the user,  \\nwhat is the criteria they may use which satisfy their need. For instance, we could be  \\ninterested in finding representatives for homogeneous groups (data reduction), in finding  \\n“natural clusters” and describe their unkn own properties (“natural” data types), in finding  \\nuseful and suitable groupings (“useful” data classes) or in finding unusual data objects  \\n(outlier detection). This algorithm must make some assumptions that constitute the \\nsimilarity of points and each assumption make different and equally valid clusters. \\nClustering Methods : \\n• Density-Based Methods: These methods consider the clusters as the dense region having  \\nsome similarities and differences from the lower dense region of the space. These \\nmethods have good accuracy and the ability to merge two clusters. Example DBSCAN \\n(Density-Based Spatial Clustering of Applications with Noise) , OPTICS (Ordering Points \\nto Identify Clustering Structure), etc. \\n• Hierarchical Based Methods: The clusters formed in this method form a treetype \\nstructure based on the hierarchy. New clusters are formed using the previously formed  \\none. It is divided into two category \\n• Agglomerative (bottom-up approach) \\n• Divisive (top-down approach) \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d8a0c528-e81e-4b90-a753-5b272155466e', embedding=None, metadata={'page_label': '75', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n69 \\n \\n \\nexamples CURE (Clustering Using Representatives), BIRCH (Balanced Iterative \\nReducing Clustering and using Hierarchies), etc. \\n• Partitioning Methods: These methods partition the objects into k clusters and each  \\npartition forms one cluster. This method is used to optimize an objective criterion \\nsimilarity function such as when the distance is a major parameter example K-means, \\nCLARANS (Clustering Large Applications based upon Randomized Search), etc. \\n• Grid-based Methods: In this method, the data space is formulated into a finite number of  \\ncells that form a grid -like structure. All the clustering operations done on these grids are  \\nfast and independent of the number of data objects example STING (Statistical \\nInformation Grid), wave cluster, CLIQUE (CLustering In Quest), etc. \\n \\n \\n \\n \\nK means Clustering: \\nIt is the simplest unsupervised learning algorithm that solves clustering problem.K -means \\nalgorithm partitions n observations into k clusters where each observation belongs to the  \\ncluster with the nearest mean serving as a prototype of the cluster. \\n \\nApplications of Clustering in different fields \\n• Marketing: It can be used to characterize & discover customer segments for marketing  \\npurposes. \\n• Biology: It can be used for classification among different species of plants and animals. \\n• Libraries: It is used in clustering different books on the basis of topics and information. \\n• Insurance: It is used to acknowledge the customers, their policies and identifying the  \\nfrauds. \\n• City Planning: It is used to make groups of houses and to study their values based on \\ntheir geographical locations and other factors present. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e0ff4073-d76b-4ed4-9b21-4b217b40629b', embedding=None, metadata={'page_label': '76', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n70 \\n \\n \\n• Earthquake studies: By learning the earthquake-affected areas we can determine the \\ndangerous zones. \\nThe algorithm will categorize the items into k groups of similarity. To calculate  \\nthat similarity, we will use the euclidean distance as measurement. The algorithm  \\nworks as follows: \\n \\n1. First, we initialize k points, called means, randomly. \\n2. We categorize each item to its closest mean and we update the mean’s coordinates, which  \\nare the averages of the items categorized in that mean so far. \\n3. We repeat the process for a given number of iterations and at the end, we have our  \\nclusters. \\nThe “points” mentioned above are called means because they hold the mean values of the  \\nitems categorized in them. To initialize these means, we have a lot of options. An intuitive  \\nmethod is to initialize the means at random items in the data set. Another method is to  \\ninitialize the means at random values between the boundaries of the data set (if for a  \\nfeature x the items have values in [0,3], we will initialize the means with values for x at \\n[0,3]). \\n \\n \\n \\nThe above algorithm in pseudocode: \\n \\n \\n \\n \\nK-MODE CLUSTERING \\nKModes clustering is one of the unsupervised Machine Learning algorithms that is used to  \\ncluster categorical variables. \\nHow does the KModes algorithm work? \\n \\n1. Pick K observations at random and use them as leaders/clusters \\n2. Calculate the dissimilarities and assign each observation to its closest cluster \\n3. Define new modes for the clusters \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b3d068b8-3716-477e-be43-8d8bf2e0fb75', embedding=None, metadata={'page_label': '77', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n71 \\n \\n \\n4. Repeat 2–3 steps until there are is no re-assignment required \\nExample: Imagine we have a dataset that has the information about hair color, eye color, and  \\nskin color of persons. We aim to group them based on the available information(maybe we  \\nwant to suggest some styling ideas) \\nHair color, eye color, and skin color are all categorical variables. Below  is how our dataset  \\nlooks like. \\n \\n \\nAlright, we have the sample data now. Let us proceed by defining the number of  \\nclusters(K)=3 \\nStep 1: Pick K observations at random and use them as leaders/clusters  \\nI am choosing P1, P7, P8 as leaders/clusters \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep 2: Calculate the dissimilarities(no. of mismatches) and assign each observation to its  \\nclosest cluster \\nIteratively compare the cluster data points to each of the observations. Similar data points  \\ngive 0, dissimilar data points give 1. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='baf9c05d-f03f-477e-839f-7925f083da06', embedding=None, metadata={'page_label': '78', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n72 \\n \\n \\n \\n \\n \\nComparing leader/Cluster P1 to the observation P1 gives 0 dissimilarities \\n \\nComparing leader/cluster P1 to the observation P2 gives 3(1+1+1) \\ndissimilarities. Likewise, calculate all the dissimilarities and put them in a matrix as shown  \\nbelow and assign the observations to their closest cluster (cluster that has the least \\ndissimilarity) \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='44350c88-35ea-4a41-8837-8dd395621e55', embedding=None, metadata={'page_label': '79', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n73 \\n \\n \\nAfter step 2, the observations P1, P2, P5 are assigned to cluster 1; P3, P7 are assigned to  \\nCluster 2; and P4, P6, P8 are assigned to cluster 3. \\nStep 3: Define new modes for the clusters \\nMode is simply the most observed value. Mark the observations according to the cluster  \\nthey belong to. Observations of Cluster 1 are marked in Yellow, Cluster 2 are marked in  \\nBrick red, and Cluster 3 are marked in Purple. \\n \\nConsidering one cluster at a time, for each feature, look for the Mode and update the new  \\nleaders. \\n \\nExplanation: Cluster 1 observations( P1, P2, P5) has brunette as the most observed hair  \\ncolor, amber as the most observed eye color, and fair as the most observed skin color. \\nBelow are our new leaders after the update. \\n \\n \\nRepeat steps 2 –4 : After obtaining the new leaders, again calculate the  dissimilarities \\nbetween the observations and the newly obtained leaders. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f6734b55-1ac0-4818-8d65-87b2b6dec518', embedding=None, metadata={'page_label': '80', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n74 \\n \\n \\n \\n \\n \\nComparing Cluster 1 to the observation P1 gives 1 dissimilarity. \\n \\n \\n \\nComparing Cluster 1 to the observation P2 gives 2 dissimilarities. \\n \\nLikewise, calculate all the dissimilarities and put them in a matrix. Assign each \\nobservation to its closest cluster. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='1e36866c-4de8-4008-ab5b-d59e31a4847e', embedding=None, metadata={'page_label': '81', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n75 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe observations P1, P2, P5 are assigned to Cluster 1; P3, P7 are assigned to Cluster 2; \\nand P4, P6, P8 are assigned to Cluster 3. \\n \\n \\n \\n \\nWe stop here as we see there is no change in the assignment of observations.  \\nImplementation of KModes in Python: \\nBegin with Importing necessary libraries ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2ac45f33-85b1-4fb9-9650-268e119740ca', embedding=None, metadata={'page_label': '82', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n76 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nVector Quantization \\nLearning Vector Quantization ( or LVQ ) is a type of Artificial Neural Network which  \\nalso inspired by biological models of neural systems. It is based on prototype supervised  \\nlearning classification algorithm and trained its network through a competitive learning  \\nalgorithm similar to Self Organizing Map. It can also deal with the multiclass \\nclassification problem. LVQ has two layers, one is the Input layer and the other one is the  \\nOutput layer. The architecture of the Learning Vector Quantization with the number of  \\nclasses in an input data and n number of input features for any sample is given below: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='0292f787-6f6e-4b9e-94ef-5d094eef1de0', embedding=None, metadata={'page_label': '83', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n77 \\n \\n \\ni \\n \\n \\n \\n \\n \\nLet say an input data of size ( m, n ) where m is number of training example and n is the  \\nnumber of features in each example and a label vector of size ( m, 1 ). First, it initializes  \\nthe weights of size ( n, c ) from the first c number of training samples with different labels  \\nand should be discarded from all trai ning samples. Here, c is the number of classes. Then  \\niterate over the remaining input data, for each training example, it updates the winning  \\nvector ( weight vector with the shortest distance ( e.g Euclidean distance ) from training  \\nexample ). Weight updation rule is given by : \\nwij = wij(old) - alpha(t) * (x k - wij(old)) \\n \\nwhere alpha is a learning rate at time t, j denotes the winning vector, i denotes the i th \\nfeature of training example and k denotes the k th training example from the input data.  \\nAfter training the LVQ network, trained weights are used for classifying new examples.  \\nA new example labeled with the class of winning vector. \\n \\nAlgorithm \\n \\nSteps involved are : \\n• Weight initialization \\n• For 1 to N number of epochs \\n• Select a training example \\n• Compute the winning vector \\n• Update the winning vector \\n• Repeat steps 3, 4, 5 for all training example. \\n• Classify test sample \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='07b28c11-2247-47cc-a650-3ecfc0336aa3', embedding=None, metadata={'page_label': '84', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n \\n \\n \\n \\nGenetic Algorithms \\nUNIT- V \\n \\n \\nGenetic Algorithms(GAs)  are adaptive heuristic search  algorithms that \\nbelong to the larger part of evolutionary algorithms. Genetic algorithms \\nare based on the ideas of natural selection and genetics. These are \\nintelligent exploitation of random search provided with historical data to  \\ndirect the search into the region of better performance in solution space.  \\nThey are commonly used to generate high-quality solutions for \\noptimization problems and search problems. \\nGenetic algorithms simulate the process of natural selection which means  \\nthose species who can adapt to changes in their environment are able to  \\nsurvive and reproduce and go to next generation. In simple words, they  \\nsimulate “survival of the fittest” among individual of consecutive \\ngeneration for solving a problem. Each generation consist of a population  \\nof individuals and each individual represents a point in search space and  \\npossible solution. Each individual is represented as a string of \\ncharacter/integer/float/bits. This string is analogous to the Chromosome. \\nDifferent search methods for induction \\nIn the field of  machine learning , an induction  algorithm represents an  \\nexample of using mathematical principles for the development of \\nsophisticated computing systems. Machine learning systems go beyond a  \\nsimple “rote input/output” function, and evolve the results that they supply  \\nwith continued use. Induction algorithms can help with the real-time \\nhandling of sophisticated data sets, or more long-term efforts. \\n \\nThe induction algorithm is something that applies to systems that show  \\ncomplex results depending on what they are set up for. One of the most  \\nfundamental ways that engineers use an induction algorithm is to enhance  \\nknowledge acquisition in a given system. In other words, with the \\nalgorithm in place, the set of “knowledge data” that end users get is \\nsomehow improved, whether that’s  regarding the quantity  of data, the  \\nfiltering of noise and undesirable results, or the refinement of some data  \\npoints. \\nMachine Learning R20D5803 ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a62716c8-d963-4c54-8ca2-47e8da94c68a', embedding=None, metadata={'page_label': '85', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Department of CSE MRCET \\n79 \\n \\n \\nAlthough the technical descriptions of induction algorithms are largely the  \\nterritory of mathematical and scientific journals, one of the basic ideas  \\nabout using the induction algorithm is that it can organize “classification  \\nrules” according to the induction principle and separate corollary  results \\nfrom different kinds of \\n \\nsystem noise or exceptions. Filtering out noise from a domain is a \\nprominent use of the induction algorithm in general. There is the idea that  \\nin real-world data filtering , induction algorithms can compose different \\nsets of rules for both the legitimate results and the system noise, in order to  \\ndistinguish one from the other. \\n \\nBy setting up induction algorithms according to certain training examples,  \\nstakeholders are looking for the ability of these systems to identify and  \\nassess consistent rules and data  that represents exceptions to these rules. In  \\na sense, the use of an induction algorithm uses the induction principle to  \\n“prove” certain results that can aid knowledge, because they provide more  \\nmarked delineations in a data set (or multiple data sets) – distinctions that \\ncan drive all sorts of end user capabilities. \\n \\nLike other kinds of machine learning software, induction algorithms are  \\noften thought of as a form of “decision support.” \\n \\n“We consider the principal task of a real -world induction system to be  \\nassisting the expert in expressing his or her expertise,” write the authors of  \\na Turing Institute paper on induction in machine learning back in the  \\n1980s. “Consequently, we require that the induced rules are highly \\npredictive and are easily comprehensible to the expert.” \\n \\nWith this in mind, induction algorithms can be part of many kinds of  \\nsoftware products that seek to refine data and produce evolving results for  \\nhuman users. In general, machine learning and the use of visual \\ndashboards is generating new t ools through which users can more rapidly  \\ndevelop in-depth knowledge about any given system, whether it's related \\nto marine research, medical diagnosis, e-commerce, or any other kind of  \\ndata-rich system. \\n \\nExplanation-Based Learning (EBL) \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c37ede87-24dc-4229-ab1e-0e6e4ebe26a9', embedding=None, metadata={'page_label': '86', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n80 \\n \\n \\nIn simple terms, it is the ability to gain basic problem -solving techniques \\nby observing and analysing solutions to specific problems. In terms of  \\nMachine Learning, it is an algorithm that aims to understand why an  \\nexample is a part of a particular concept to make generalizations or form  \\nconcepts from training examples. For example, EBL uses a domain \\ntheory and creates a program that learns to play chess.  EBL involves 2  \\nsteps: \\n1. Explanation — The domain theory is used to eliminate all the unimportant  \\ntraining example while retaining the important ones that best describe the goal  \\nconcept. \\n2. Generalization — The explanation of the goal concept is made as general \\nand widely applicable as possible. This ensures that all cases are covered,  \\nnot just certain specific ones. \\nEBL Architecture: \\n• EBL model during training \\n• During training, the model generalizes the training example in such a way that  \\nall scenarios lead to the Goal Concept, not just in specific cases. (As shown in \\nFig 1) ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='151b4539-58e2-463a-b19c-d62774b99843', embedding=None, metadata={'page_label': '87', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n81 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• EBL model after training \\n• Post training, EBL model tends to directly reach the hypothesis space involving \\nthe goal concept.  (As shown in Fig 2) \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='21342a23-043e-411a-8b55-ec4d2d104469', embedding=None, metadata={'page_label': '88', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n82 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nDimensionality Reduction \\nAn intuitive example of dimensionality reduction can be discussed through  \\na simple e-mail classification problem, where we need to classify whether  \\nthe e-mail is spam or not. This can involve a large number of features, \\nsuch as whether or not the e -mail has a generic title, the content of the e - \\nmail, whether the e -mail uses a tem plate, etc. However, some of these  \\nfeatures may overlap. In another condition, a classification problem that  \\nrelies on both humidity and rainfall can be collapsed into just one \\nunderlying feature, since both of the aforementioned are correlated to a  \\nhigh degree. Hence, we can reduce the number of features in such \\nproblems. A 3D classification problem can be hard to visualize, whereas a  \\n2-D one can  be mapped to a simple 2  dimensional space, and  a 1 -D \\nproblem to a simple line. The below figure illustrates this concept, where a  \\n3-D feature space is split into two 1 -D feature spaces, and later, if found to  \\nbe correlated, the number of features can be reduced even further. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='32bd74b9-05cb-46d6-aad3-0d2d928f966f', embedding=None, metadata={'page_label': '89', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n83 \\n \\n \\n \\n \\n \\n \\n \\nComponents of Dimensionality \\nReduction There are two components of dimensionality  \\nreduction: \\n• Feature selection: In this, we try to find a subset of the original set of variables,  \\nor features, to get a smaller subset which can be used to model the problem. It  \\nusually involves three ways: \\n1. Filter \\n2. Wrapper \\n3. Embedded \\n• Feature extraction: This reduces the data in a high dimensional space to a \\nlower dimension space, i.e. a space with lesser no. of dimensions. \\nMethods of Dimensionality Reduction The various \\nmethods used for dimensionality reduction include: \\n• Principal Component Analysis (PCA) \\n• Linear Discriminant Analysis (LDA) \\n• Generalized Discriminant Analysis (GDA) \\nDimensionality reduction may be both linear or non-linear, depending \\nupon the method used. The prime linear method, called Principal \\nComponent Analysis, or PCA, is discussed below. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fe94d808-06e1-4216-b857-d256addfc49f', embedding=None, metadata={'page_label': '90', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n84 \\n \\n \\n \\nPrincipal Component Analysis \\nThis method was introduced by Karl Pearson. It works on a condition that  \\nwhile the data in a higher dimensional space is mapped to data in a lower  \\ndimension space, the variance of the data in the lower dimensional space  \\nshould be maximum. \\n \\nIt involves the following steps: \\n• Construct the covariance matrix of the data. \\n• Compute the eigenvectors of this matrix. \\n• Eigenvectors corresponding to the largest eigenvalues are used to reconstruct a  \\nlarge fraction of variance of the original data. \\nHence, we are left with a lesser number of eigenvectors, and there might  \\nhave been some data loss in the process. But, the most important variances  \\nshould be retained by the remaining eigenvectors. \\nAdvantages of Dimensionality Reduction \\n• It helps in data compression, and hence reduced storage space. \\n• It reduces computation time. \\n• It also helps remove redundant features, if any. Disadvantages of \\nDimensionality Reduction • It may lead to some amount of data loss. \\n• PCA tends to find linear correlations between variables, which is sometimes \\nundesirable. \\n• PCA fails in cases where mean and covariance are not enough to define \\ndatasets. \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6e6f8349-5b27-4d94-a335-42cd4607a322', embedding=None, metadata={'page_label': '91', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n85 \\n \\n \\n• We may not know how many principal components to keep- in practice, some \\nthumb rules are applied. \\n \\n \\n \\nFactor analysis. \\nFactor analysis is a statistical method used to describe variability among \\nobserved, correlated variables in terms of a potentially lower number of \\nobserved variables called factors. For example, it is possible that variations in  \\nsix observed variables mainly reflect the variations in two unobserved \\n(underlying) variables. Factor analysis searches for such joint variations in  \\nresponse to unobserved latent variables. The observed variables are modelled  \\nas linear combinations of the potential factors plus \"error\" terms, hence factor  \\nanalysis can be thought of as a special case of errors-invariables models. \\n \\nHere,There is a party going into a room full of people. There is ‘n’ number of  \\nspeakers in that room and they are speaking simultaneously at the party. In the  \\nsame room, there are also ‘n’ number of microphones placed at different \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5d4fc4dc-1183-46ff-ad18-e096b41f03d1', embedding=None, metadata={'page_label': '92', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n86 \\n \\n \\ndistances from the speakers which are recording ‘n’ speakers’ voice signals.  \\nHence, the number of speakers is equal to the number must of microphones in \\nthe room. \\nNow, using these microphones’ recordings,  we want to separate all the ‘n’  \\nspeakers’ voice signals in the room given each microphone recorded the voice  \\nsignals coming from each speaker of different intensity due to the difference in  \\ndistances between them. Decomposing the mixed signal of each microphone’s  \\nrecording into independent source’s speech signal can be done by using the  \\nmachine learning technique, independent component analysis. \\n[ X1, X2, ….., Xn ] => [ Y1, Y2, ….., Yn ] \\nwhere, X1, X2,  …, Xn are the original signals present in the mixed signal and  \\nY1, Y2, …, Yn are the new features and are independent components which are  \\nindependent of each other. \\n \\n \\n \\nRestrictions on ICA \\n \\n1. The independent components generated by the ICA are assumed to be \\nstatistically independent of each other. \\n2. The independent components generated by the ICA must have non -gaussian \\ndistribution. \\n3. The number of independent components generated by the ICA is equal to the \\nnumber of observed mixtures. \\n \\nMultidimensional scaling \\nMultidimensional scaling is a visual representation of distances or \\ndissimilarities between sets of objects. \\n“Objects” can be colors, faces, map coordinates, political persuasion, or any \\nkind of real or conceptual stimuli \\n(Kruskal and Wish, 1978). Objects that are more similar (or have shorter \\ndistances) are closer together on the graph than objects that are less similar (or  \\nhave longer distances). As well as interpreting dissimilarities as distances on a ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='58478417-a4bf-4920-b71f-5e17aa048bb4', embedding=None, metadata={'page_label': '93', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n87 \\n \\n \\ngraph, MDS can also serve as a dimension reduction technique for high- \\ndimensional data (Buja et. al, 2007). \\nThe term scaling comes from psychometrics, where abstract concepts \\n(“objects”) are assigned numbers according to a rule (Trochim, 2006). For \\nexample, you may want to quantify a person’s attitude to global warming. You  \\ncould a ssign a “1” to “doesn’t believe in global warming”, a 10 to “firmly  \\nbelieves in global warming” and a scale of 2 to 9 for attitudes in between. You  \\ncan also think of “scaling” as the fact that you’re essentially scaling down the  \\ndata (i.e. \\nmaking it simpler by creating lower -dimensional data). Data that is scaled down  \\nin dimension keeps similar properties. For example, two data points that are  \\nclose together in high-dimensional space will also be close together in low - \\ndimensional space (Martinez, 2005). The “ multidimensional” part is du e to the \\nfact that you aren’t limited to two dimensional graphs or data. Three- \\ndimensional, four-dimensional and higher plots are possible. \\nMDS is now used over a wide variety of disciplines. It’s use isn’t limited to a  \\nspecific matrix or set of data; In fact, just about any matrix can be analyzed with  \\nthe technique as long as the matrix contains some type of relational data \\n(Young, 2013). Examples of relational data include correlations, distances, \\nmultiple rating scales or similarities. \\nManifold learning \\n \\nWhat is a manifold? \\n \\nA two-dimensional manifold is any 2-D shape that can be made to fit in a higher \\ndimensional space by twisting or bending it, loosely speaking. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='47ad960e-4f55-4d14-962c-d5ed62a0518c', embedding=None, metadata={'page_label': '94', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n88 \\n \\n \\nWhat is the Manifold Hypothesis? \\n \\n“The Manifold Hypothesis states that real-world high-dimensional data lie on \\nlow dimensional manifolds embedded within the high-dimensional space.” \\nIn simpler terms, it means that higher-dimensional data most of the time lies on \\na much closer lower-dimensional manifold. The process of modelling the \\nmanifold on which training instances lie is called Manifold Learning. \\nLocally Linear Embedding (LLE) \\n \\nLocally Linear Embedding (LLE) is a Manifold Learning technique that is used  \\nfor non-linear dimensionality reduction. It is an unsupervised learning algorithm \\nthat produces low-dimensional embeddings of high-dimensional inputs, relating \\neach training instance to its closest neighbor. \\nHow does LLE work? \\n \\nFor each training instance x(i), the algorithm first finds its k nearest neighbors \\nand then tries to express x(i) as a linear function of them. In general, if there are \\nm training instances in total, then it tries to find the set of weights w which \\nminimizes the squared distance between x(i) and its linear representation. \\n \\nSo, the cost function is given by \\n \\n \\nwhere wi,j =0, if j is not included in the k closest neighbors of i. \\n \\nAlso, it normalizes the weights for each training instance x(i), \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='3d301977-6b29-4321-a59a-fd6dd6a71cf6', embedding=None, metadata={'page_label': '95', 'file_name': 'ML FINAL (1).pdf', 'file_path': 'd:\\\\Personal projects\\\\QA_With_Doc_using_llama_index_gemini\\\\Experiments\\\\..\\\\Data\\\\ML FINAL (1).pdf', 'file_type': 'application/pdf', 'file_size': 3006189, 'creation_date': '2025-01-19', 'last_modified_date': '2025-01-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Department of CSE MRCET \\n89 \\n \\n \\n \\n \\n \\nFinally, each high-dimensional training instance x(i) is mapped to a low- \\ndimensional (say, d dimensions) vector y(i) while preserving the neighborhood \\nrelationships. This is done by choosing d-dimensional coordinates which \\nminimize the cost function, \\n \\nHere the weights wi,j are kept fixed while we try to find the optimum coordinates \\ny(i) \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      " \n",
      "DIGITAL NOTES \n",
      "ON \n",
      "Machine Learning \n",
      "(R20D5803) \n",
      "M.Tech., II YEAR – I SEM \n",
      "(2021-2022) \n",
      " \n",
      " \n",
      " \n",
      "DEPARTMENT OF COMPUTER SCIENCE AND \n",
      "ENGINEERING \n",
      " \n",
      "MALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY \n",
      "(Autonomous Institution – UGC, Govt. of India) \n",
      "(Affiliated to JNTUH, Hyderabad, Approved by AICTE - Accredited by NBA & NAAC – ‘A’ Grade - ISO 9001:2015 Certified) \n",
      "Maisammaguda, Dhulapally (Post Via. Hakimpet), Secunderabad – 500100, Telangana State, INDIA.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Gemini(models='gemini-pro',api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab embeddings from gemini embeddings model\n",
    "gemini_embed_model = GeminiEmbedding(model_name=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = model\n",
    "Settings.embed_model = gemini_embed_model\n",
    "Settings.chunk_size = 1000\n",
    "Settings.chunk_overlap = 20\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "vector_store = VectorStoreIndex.from_documents(documents=documents,service_context=Settings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents,service_context=Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = query_engine.query(\"what is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This document does not contain a definition of machine learning. It only contains page numbers and department information.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = query_engine.query(\"what is attention mechnism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
